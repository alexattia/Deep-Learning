{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a ConvNet to recognize objects using the CIFAR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we train a ConvNet from scratch to do object recognition over 10 classes.\n",
    "You would learn how to use Torch's neural network package and optim package to train a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- require the necessary packages\n",
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'image'\n",
    "require 'xlua'\n",
    "\n",
    "\n",
    "torch.setdefaulttensortype('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- manually define the class-names in CIFAR-10 in a lua table\n",
    "classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- define model to train\n",
    "model = nn.Sequential()\n",
    "--[[ stage 1 : mean+std normalization -> filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(3,32,5,5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "-- stage 2 : filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(32,32,5,5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "]]\n",
    "-- stage 3 : standard 2-layer neural network\n",
    "model:add(nn.View(3*64*64))\n",
    "model:add(nn.Linear(3*64*64, #classes))\n",
    "--model:add(nn.ReLU())\n",
    "--model:add(nn.Linear(128,#classes))\n",
    "model:add(nn.LogSoftMax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> output]\n",
       "  (1): nn.View(12288)\n",
       "  (2): nn.Linear(12288 -> 11)\n",
       "  (3): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model:__tostring())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- retrieve parameters and gradients. this helps us to use the optim package\n",
    "parameters,gradParameters = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.ClassNLLCriterion\n",
       "{\n",
       "  sizeAverage : true\n",
       "  output : 0\n",
       "  gradInput : FloatTensor - empty\n",
       "  output_tensor : FloatTensor - size: 1\n",
       "  target : LongTensor - size: 1\n",
       "  total_weight_tensor : FloatTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- loss function: negative log-likelihood\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "print (criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 64 -- sets the mini-Batch size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "157\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "85\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "223\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "44\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "288\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "215\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "164\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "153\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "190\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dofile('loadData.ipy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--trainData.labels = trainData.labels + 1\n",
    "trainData.data = trainData.data:reshape(1673,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp=0\n",
    "for i=1,1672 do \n",
    "    if trainData.labels[i] == 0 then\n",
    "        temp= temp+1\n",
    "        print(i)\n",
    "    end\n",
    "end\n",
    "print (temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- preprocess/normalize train/test sets\n",
    "-- preprocess trainSet\n",
    "collectgarbage()\n",
    "\n",
    "\n",
    "\n",
    "normalization = nn.SpatialContrastiveNormalization(1, image.gaussian1D(7))\n",
    "\n",
    "for i = 1,1673 do\n",
    "   -- rgb -> yuv\n",
    "   local rgb = trainData.data[i]\n",
    "   local yuv = image.rgb2yuv(rgb)\n",
    "   -- normalize y locally:\n",
    "   yuv[1] = normalization(yuv[{{1}}])\n",
    "   trainData.data[i] = yuv\n",
    "end\n",
    "-- normalize u globally:\n",
    "mean_u = trainData.data[{ {},2,{},{} }]:mean()\n",
    "std_u = trainData.data[{ {},2,{},{} }]:std()\n",
    "trainData.data[{ {},2,{},{} }]:add(-mean_u)\n",
    "trainData.data[{ {},2,{},{} }]:div(-std_u)\n",
    "-- normalize v globally:\n",
    "mean_v = trainData.data[{ {},3,{},{} }]:mean()\n",
    "std_v = trainData.data[{ {},3,{},{} }]:std()\n",
    "trainData.data[{ {},3,{},{} }]:add(-mean_v)\n",
    "trainData.data[{ {},3,{},{} }]:div(-std_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collectgarbage()\n",
    "--trainData.data:mul(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- this matrix records the current confusion across classes\n",
    "confusion = optim.ConfusionMatrix(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- define training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- training function\n",
    "function train(dataset)\n",
    "   -- epoch tracker\n",
    "   epoch = epoch or 1\n",
    "\n",
    "   -- do one epoch\n",
    "   print('<trainer> on training set:')\n",
    "   print(\"<trainer> online epoch # \" .. epoch .. ' [batchSize = ' .. batchSize .. ']')\n",
    "   for t = 1,dataset:size(),batchSize do\n",
    "\n",
    "      -- create mini batch\n",
    "      local inputs = {}\n",
    "      local targets = {}\n",
    "      for i = t,math.min(t+batchSize-1,dataset:size()) do\n",
    "         -- load new sample\n",
    "         local input = dataset.data[i]\n",
    "         local target = dataset.labels[i]\n",
    "         table.insert(inputs, input)\n",
    "         table.insert(targets, target)\n",
    "      end\n",
    "      -- create closure to evaluate f(X) and df/dX\n",
    "      local feval = function(x)\n",
    "                       -- get new parameters\n",
    "                       if x ~= parameters then\n",
    "                          parameters:copy(x)\n",
    "                       end\n",
    "\n",
    "                       -- reset gradients\n",
    "                       gradParameters:zero()\n",
    "\n",
    "                       -- f is the average of all criterions\n",
    "                       local f = 0\n",
    "\n",
    "                       -- evaluate function for complete mini batch\n",
    "                       for i = 1,#inputs do\n",
    "                          -- estimate f\n",
    "                          local output = model:forward(inputs[i])\n",
    "                          local err = criterion:forward(output, targets[i])\n",
    "                          f = f + err\n",
    "\n",
    "                          -- estimate df/dW\n",
    "                          local df_do = criterion:backward(output, targets[i])\n",
    "                          model:backward(inputs[i], df_do)\n",
    "\n",
    "                          -- update confusion\n",
    "                          confusion:add(output, targets[i])                        \n",
    "                       end\n",
    "\n",
    "                       -- normalize gradients and f(X)\n",
    "                       gradParameters:div(#inputs)\n",
    "                       f = f/#inputs\n",
    "\n",
    "                       -- return f and df/dX\n",
    "                       return f,gradParameters\n",
    "                    end\n",
    "\n",
    "\n",
    "      config = config or {learningRate = 1e-3,\n",
    "              weightDecay = 0,\n",
    "                momentum = 0,\n",
    "              learningRateDecay = 5e-7}\n",
    "      optim.sgd(feval, parameters, config)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "   -- next epoch\n",
    "   epoch = epoch + 1\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- test function\n",
    "function test(dataset)\n",
    "\n",
    "   -- test over given dataset\n",
    "   print('<trainer> on testing Set:')\n",
    "   for t = 1,dataset:size() do\n",
    "      -- get new sample\n",
    "      local input = dataset.data[t]\n",
    "      local target = dataset.labels[t]\n",
    "\n",
    "      -- test sample\n",
    "      local pred = model:forward(input)\n",
    "      confusion:add(pred, target)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 1 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      66      12      19      10       9      17       5       8      11      11      13]   36.464% \t[class: bridge]\n",
       " [      61      38       7       4       7       4      10       5       3       5       8]   25.000% \t[class: building]\n",
       " [       9      54       9       3       0       2       3       0       0       0       1]   11.111% \t[class: city]\n",
       " [       1       8       2       1       2       0       0       1       0       0       1]   6.250% \t[class: eiffel_tower]\n",
       " [      12      32      43      13      63      10       5       3       8      14      15]   28.899% \t[class: elephant]\n",
       " [       0       0      25       1      12       1       1       1       0       1       2]   2.273% \t[class: landscape]\n",
       " [       5       8       4       0      68      14     170       3       3       1       7]   60.071% \t[class: lion]\n",
       " [       7      13      11       7      12      18      96      23      12       5       9]   10.798% \t[class: monkey]\n",
       " [      14       7       9      11      11      14      33      26      20       7       7]   12.579% \t[class: people]\n",
       " [       7       5       6       2       7      28       3       3      15      71       0]   48.299% \t[class: tower]\n",
       " [      10       5       4       3       3       5      11      24      16      43      55]]  30.726% \t[class: water]\n",
       " + average row correct: 24.769999493252% \n",
       " + average rowUcol correct (VOC measure): 15.126748124815% \n",
       " + global correct: 30.902570233114%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.15126748124815\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.24769999493252\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.30902570233114\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 2 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      67       5       6       2       3       8       6       9      11      18      46]   37.017% \t[class: bridge]\n",
       " [      64      38       4       2       5       4       9       3       2      11      10]   25.000% \t[class: building]\n",
       " [       9      48       7       3       0       1       4       3       4       2       0]   8.642% \t[class: city]\n",
       " [       3       8       0       0       2       0       0       3       0       0       0]   0.000% \t[class: eiffel_tower]\n",
       " [       7      24      31       8      80       9       6      13      11      12      17]   36.697% \t[class: elephant]\n",
       " [       2       1      18       0      18       1       2       0       0       1       1]   2.273% \t[class: landscape]\n",
       " [       3       6       8       0      66       9     176       6       1       1       7]   62.191% \t[class: lion]\n",
       " [       6       8      11       6      11      19      93      33      11       4      11]   15.493% \t[class: monkey]\n",
       " [       8       8      11       6      10      13      30      29      32       5       7]   20.126% \t[class: people]\n",
       " [       7       2      13       3       5      23       6       3      13      72       0]   48.980% \t[class: tower]\n",
       " [       9       3       5       2       4       6      11      24      17      37      61]]  34.078% \t[class: water]\n",
       " + average row correct: 26.408716900782% \n",
       " + average rowUcol correct (VOC measure): 16.423812004822% \n",
       " + global correct: 33.891213389121%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.16423812004822\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.26408716900782\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.33891213389121\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 3 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      71       4       6       1       2       4      10      10      13      21      39]   39.227% \t[class: bridge]\n",
       " [      58      44       3       1       5       5       9       4       2      11      10]   28.947% \t[class: building]\n",
       " [      10      45       9       1       0       1       4       3       4       3       1]   11.111% \t[class: city]\n",
       " [       4       7       0       0       2       0       0       3       0       0       0]   0.000% \t[class: eiffel_tower]\n",
       " [       6      23      29       6      97       7       5      14       9       6      16]   44.495% \t[class: elephant]\n",
       " [       2       0      11       0      21       5       2       0       0       2       1]   11.364% \t[class: landscape]\n",
       " [       3       6       8       0      59      11     178       7       3       1       7]   62.898% \t[class: lion]\n",
       " [       4       7      11       5       8      18      91      46      12       4       7]   21.596% \t[class: monkey]\n",
       " [       8       6      13       3      11      10      27      31      40       5       5]   25.157% \t[class: people]\n",
       " [       5       2      14       2       6      21       6       2      14      74       1]   50.340% \t[class: tower]\n",
       " [       8       2       5       1       4       6      12      23      16      34      68]]  37.989% \t[class: water]\n",
       " + average row correct: 30.284001339566% \n",
       " + average rowUcol correct (VOC measure): 18.961847641251% \n",
       " + global correct: 37.776449491931%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.18961847641251\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.30284001339566\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.37776449491931\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 4 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      74       4       6       1       2       5      11       8      11      23      36]   40.884% \t[class: bridge]\n",
       " [      50      53       1       0       5       5       9       5       4      11       9]   34.868% \t[class: building]\n",
       " [      10      46       9       1       0       1       4       3       4       3       0]   11.111% \t[class: city]\n",
       " [       3       6       0       0       2       1       0       3       1       0       0]   0.000% \t[class: eiffel_tower]\n",
       " [       7      21      24       6     102       9       8      19      10       3       9]   46.789% \t[class: elephant]\n",
       " [       2       0       9       0      19       9       2       0       0       2       1]   20.455% \t[class: landscape]\n",
       " [       2       4       7       0      55       9     183       9       4       1       9]   64.664% \t[class: lion]\n",
       " [       3       8       9       3      13      14      87      53      12       5       6]   24.883% \t[class: monkey]\n",
       " [       5       6      14       3      13      11      25      27      45       5       5]   28.302% \t[class: people]\n",
       " [       5       6      12       1       6      16       7       2      13      78       1]   53.061% \t[class: tower]\n",
       " [       8       3       4       1       4       7      13      25      14      32      68]]  37.989% \t[class: water]\n",
       " + average row correct: 33.000538498163% \n",
       " + average rowUcol correct (VOC measure): 20.715289122679% \n",
       " + global correct: 40.286909742977%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.20715289122679\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.33000538498163\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.40286909742977\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 5 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      77       2       6       1       2       5      11       7      13      23      34]   42.541% \t[class: bridge]\n",
       " [      48      60       1       0       4       6       9       5       4      10       5]   39.474% \t[class: building]\n",
       " [      10      43      13       1       0       1       4       3       3       3       0]   16.049% \t[class: city]\n",
       " [       2       5       0       0       2       1       2       2       1       1       0]   0.000% \t[class: eiffel_tower]\n",
       " [       6      17      20       6     111      10       8      18      10       3       9]   50.917% \t[class: elephant]\n",
       " [       2       0      10       1      15      13       1       0       0       1       1]   29.545% \t[class: landscape]\n",
       " [       3       4       5       0      48       9     192      10       4       1       7]   67.845% \t[class: lion]\n",
       " [       2       7      11       2      12      10      80      63      15       5       6]   29.577% \t[class: monkey]\n",
       " [       5       5      15       3      15       9      22      23      52       5       5]   32.704% \t[class: people]\n",
       " [       4       9      13       1       4      13       8       2      11      80       2]   54.422% \t[class: tower]\n",
       " [       8       3       4       1       5       6      14      24      13      32      69]]  38.547% \t[class: water]\n",
       " + average row correct: 36.511184681546% \n",
       " + average rowUcol correct (VOC measure): 23.165978423574% \n",
       " + global correct: 43.634190077705%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.23165978423574\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.36511184681546\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.43634190077705\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 6 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      78       3       5       1       3       5      11       6      12      24      33]   43.094% \t[class: bridge]\n",
       " [      42      64       1       1       3       6       9       5       6      10       5]   42.105% \t[class: building]\n",
       " [      10      42      14       1       1       0       4       3       3       3       0]   17.284% \t[class: city]\n",
       " [       2       6       0       1       1       1       2       2       1       0       0]   6.250% \t[class: eiffel_tower]\n",
       " [       6      19      15       7     118       8       8      17       8       3       9]   54.128% \t[class: elephant]\n",
       " [       2       0      10       1      12      16       1       0       0       1       1]   36.364% \t[class: landscape]\n",
       " [       2       5       5       0      47       8     193      11       5       1       6]   68.198% \t[class: lion]\n",
       " [       2       8      11       2      11       7      75      71      15       5       6]   33.333% \t[class: monkey]\n",
       " [       4       4      15       4      15       8      22      20      58       4       5]   36.478% \t[class: people]\n",
       " [       4      10      11       0       4      12       8       2      11      83       2]   56.463% \t[class: tower]\n",
       " [       6       4       4       2       5       7      16      21      13      30      71]]  39.665% \t[class: water]\n",
       " + average row correct: 39.396527815949% \n",
       " + average rowUcol correct (VOC measure): 25.150633281605% \n",
       " + global correct: 45.84578601315%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.25150633281605\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.39396527815949\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.4584578601315\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 7 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      80       4       4       1       4       5      11       6      12      24      30]   44.199% \t[class: bridge]\n",
       " [      40      66       1       1       4       6       9       6       7       8       4]   43.421% \t[class: building]\n",
       " [       8      41      16       1       0       0       5       3       4       3       0]   19.753% \t[class: city]\n",
       " [       2       6       0       1       1       1       2       2       1       0       0]   6.250% \t[class: eiffel_tower]\n",
       " [       6      19      14       5     126       6       6      16       8       3       9]   57.798% \t[class: elephant]\n",
       " [       2       1       8       0      12      18       1       0       0       1       1]   40.909% \t[class: landscape]\n",
       " [       2       5       4       0      42       7     199      11       5       2       6]   70.318% \t[class: lion]\n",
       " [       2       7      11       2       9       6      71      79      14       5       7]   37.089% \t[class: monkey]\n",
       " [       3       4      13       4      15       8      21      17      66       4       4]   41.509% \t[class: people]\n",
       " [       5      11      10       0       3      11       8       2      10      85       2]   57.823% \t[class: tower]\n",
       " [       4       3       4       3       4       7      17      20      12      28      77]]  43.017% \t[class: water]\n",
       " + average row correct: 42.007893865759% \n",
       " + average rowUcol correct (VOC measure): 27.268075807528% \n",
       " + global correct: 48.595337716677%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.27268075807528\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.42007893865759\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "    8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.48595337716677\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 8 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      85       4       2       1       4       4      11       6      10      25      29]   46.961% \t[class: bridge]\n",
       " [      39      68       1       1       4       6       9       6       6       6       6]   44.737% \t[class: building]\n",
       " [       9      38      20       1       0       1       4       2       2       4       0]   24.691% \t[class: city]\n",
       " [       2       5       0       2       1       1       2       2       1       0       0]   12.500% \t[class: eiffel_tower]\n",
       " [       5      20      12       4     134       6       6      13       9       2       7]   61.468% \t[class: elephant]\n",
       " [       1       2       7       0      10      21       1       0       0       1       1]   47.727% \t[class: landscape]\n",
       " [       2       5       4       0      41       4     204      10       5       2       6]   72.085% \t[class: lion]\n",
       " [       2       7      10       2       8       6      68      83      13       6       8]   38.967% \t[class: monkey]\n",
       " [       3       4      12       3      16       8      20      15      71       3       4]   44.654% \t[class: people]\n",
       " [       5      11       9       0       2      10       9       2       8      89       2]   60.544% \t[class: tower]\n",
       " [       4       3       4       3       5       6      16      19      12      27      80]]  44.693% \t[class: water]\n",
       " + average row correct: 45.366152308204% \n",
       " + average rowUcol correct (VOC measure): 29.760081795129% \n",
       " + global correct: 51.225343693963%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.29760081795129\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.45366152308204\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.51225343693963\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 9 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      93       4       1       1       4       3      11       5       9      24      26]   51.381% \t[class: bridge]\n",
       " [      36      76       1       1       3       6       7       6       5       6       5]   50.000% \t[class: building]\n",
       " [      10      35      23       0       0       1       4       2       2       4       0]   28.395% \t[class: city]\n",
       " [       2       5       0       2       1       1       2       2       1       0       0]   12.500% \t[class: eiffel_tower]\n",
       " [       4      18      12       4     140       4       5      13      10       2       6]   64.220% \t[class: elephant]\n",
       " [       0       2       8       0       8      23       1       0       0       1       1]   52.273% \t[class: landscape]\n",
       " [       2       4       4       0      38       3     207      10       6       2       7]   73.145% \t[class: lion]\n",
       " [       2       8       8       2       7       4      66      90      13       6       7]   42.254% \t[class: monkey]\n",
       " [       3       3      11       2      15       8      17      14      81       2       3]   50.943% \t[class: people]\n",
       " [       5      10       8       0       2      10       8       3       7      92       2]   62.585% \t[class: tower]\n",
       " [       3       3       3       2       4       6      16      18      13      26      85]]  47.486% \t[class: water]\n",
       " + average row correct: 48.65291389552% \n",
       " + average rowUcol correct (VOC measure): 32.671847194433% \n",
       " + global correct: 54.512851165571%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.32671847194433\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.4865291389552\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.54512851165571\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 10 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      97       4       1       0       5       3      10       5       9      22      25]   53.591% \t[class: bridge]\n",
       " [      34      79       1       1       3       6       9       6       4       5       4]   51.974% \t[class: building]\n",
       " [      10      32      27       0       0       1       4       1       2       4       0]   33.333% \t[class: city]\n",
       " [       2       5       0       2       1       1       2       2       1       0       0]   12.500% \t[class: eiffel_tower]\n",
       " [       4      16      12       4     144       4       5      12       9       2       6]   66.055% \t[class: elephant]\n",
       " [       0       4       6       1       8      23       1       0       0       0       1]   52.273% \t[class: landscape]\n",
       " [       2       4       4       0      36       3     211       8       6       1       8]   74.558% \t[class: lion]\n",
       " [       1       9       7       2       7       4      65      92      13       6       7]   43.192% \t[class: monkey]\n",
       " [       3       3      12       2      13       7      16      13      86       2       2]   54.088% \t[class: people]\n",
       " [       3      10       7       0       2      10       8       3       7      95       2]   64.626% \t[class: tower]\n",
       " [       3       2       2       1       5       9      16      17      13      25      86]]  48.045% \t[class: water]\n",
       " + average row correct: 50.385031104088% \n",
       " + average rowUcol correct (VOC measure): 34.241173619574% \n",
       " + global correct: 56.306037059175%\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.34241173619574\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.50385031104088\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.56306037059175\n",
       "}\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "while i<10 do\n",
    "train(trainData)\n",
    "i=i+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save('model1layer.net',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15544034851502\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.16365542069888\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save('model1.net', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trainer> on testing Set:\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      24       8       8       5       2       2       8       6      24      16]   23.301% \t[class: airplane]\n",
       " [       4      58       1       4       0       0       7       4       1      10]   65.169% \t[class: automobile]\n",
       " [       5       5      28      11       8       4      20       7       8       4]   28.000% \t[class: bird]\n",
       " [       3       7      11      30       3       6      30       3       5       5]   29.126% \t[class: cat]\n",
       " [       4       1      10       8      12       1      37      11       4       2]   13.333% \t[class: deer]\n",
       " [       1       5       9      25       4      10      20       4       3       5]   11.628% \t[class: dog]\n",
       " [       0       1       3      20       3       5      71       2       3       4]   63.393% \t[class: frog]\n",
       " [       5       3       7       8       7       6      13      47       2       4]   46.078% \t[class: horse]\n",
       " [      22       9       4       6       2       0       1       4      51       7]   48.113% \t[class: ship]\n",
       " [       9      38       3       7       2       3       5       7       4      31]]  28.440% \t[class: truck]\n",
       " + average row correct: 35.658183768392% \n",
       " + average rowUcol correct (VOC measure): 21.221470534801% \n",
       " + global correct: 36.2%\n",
       "{\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : FloatTensor - size: 10x10\n",
       "  averageUnionValid : 0.21221470534801\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.35658183768392\n",
       "  classes : \n",
       "    {\n",
       "      1 : airplane\n",
       "      2 : automobile\n",
       "      3 : bird\n",
       "      4 : cat\n",
       "      5 : deer\n",
       "      6 : dog\n",
       "      7 : frog\n",
       "      8 : horse\n",
       "      9 : ship\n",
       "      10 : truck\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 0.362\n",
       "}\n",
       "0.2776620388031\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "test(testData)\n",
    "print (timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9\t\n"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.labels[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: airplane]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: automobile]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: bird]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: cat]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: deer]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: dog]\n",
       " [       0       0       0       0       0       0       1       0       0       0]   100.000% \t[class: frog]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: horse]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: ship]\n",
       " [       0       0       0       0       0       0       0       0       0       0]]  nan% \t[class: truck]\n",
       " + average row correct: 100% \n",
       " + average rowUcol correct (VOC measure): 100% \n",
       " + global correct: 100%\n",
       "{\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : FloatTensor - size: 10x10\n",
       "  averageUnionValid : 1\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 1\n",
       "  classes : \n",
       "    {\n",
       "      1 : airplane\n",
       "      2 : automobile\n",
       "      3 : bird\n",
       "      4 : cat\n",
       "      5 : deer\n",
       "      6 : dog\n",
       "      7 : frog\n",
       "      8 : horse\n",
       "      9 : ship\n",
       "      10 : truck\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 1\n",
       "}\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "j=50\n",
    "confusion:zero()\n",
    "\n",
    "\n",
    "itorch.image(testData.data[j])\n",
    "inp= testData.data[j]\n",
    "tar= testData.labels[j]\n",
    "\n",
    "pred = model:forward(inp)\n",
    "confusion:add(pred, tar)\n",
    "print(confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1657\n",
       "-2.3892\n",
       "-2.5634\n",
       "-4.5198\n",
       "-4.0242\n",
       "-5.7736\n",
       "-6.7106\n",
       "-5.2705\n",
       "-0.9884\n",
       "-2.2155\n",
       "[torch.DoubleTensor of dimension 10]\n",
       "\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"for (i=1,100 and i~=5) do...\"]:1: '<name>' expected near '('",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"for (i=1,100 and i~=5) do...\"]:1: '<name>' expected near '('"
     ]
    }
   ],
   "source": [
    "for i=1,100 and i~=5) do\n",
    "    print(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1~=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
