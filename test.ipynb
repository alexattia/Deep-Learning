{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a ConvNet to recognize objects using the CIFAR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we train a ConvNet from scratch to do object recognition over 10 classes.\n",
    "You would learn how to use Torch's neural network package and optim package to train a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- require the necessary packages\n",
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'image'\n",
    "require 'xlua'\n",
    "\n",
    "\n",
    "torch.setdefaulttensortype('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- manually define the class-names in CIFAR-10 in a lua table\n",
    "classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- define model to train\n",
    "model = nn.Sequential()\n",
    "--[[ stage 1 : mean+std normalization -> filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(3,32,5,5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "-- stage 2 : filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(32,32,5,5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "]]\n",
    "-- stage 3 : standard 2-layer neural network\n",
    "model:add(nn.View(3*64*64))\n",
    "model:add(nn.Linear(3*64*64, #classes))\n",
    "--model:add(nn.ReLU())\n",
    "--model:add(nn.Linear(128,#classes))\n",
    "model:add(nn.LogSoftMax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> output]\n",
       "  (1): nn.View(12288)\n",
       "  (2): nn.Linear(12288 -> 11)\n",
       "  (3): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model:__tostring())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- retrieve parameters and gradients. this helps us to use the optim package\n",
    "parameters,gradParameters = model:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.ClassNLLCriterion\n",
       "{\n",
       "  sizeAverage : true\n",
       "  output : 0\n",
       "  gradInput : FloatTensor - empty\n",
       "  output_tensor : FloatTensor - size: 1\n",
       "  target : LongTensor - size: 1\n",
       "  total_weight_tensor : FloatTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- loss function: negative log-likelihood\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "print (criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 64 -- sets the mini-Batch size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "157\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "85\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "223\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "44\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "288\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "215\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "164\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "153\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "190\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "imagesAll = torch.Tensor(1721,3,64,64) \n",
    "labelsAll = torch.IntTensor(1721)\n",
    "compteur = 0\n",
    "compteur2 = 0\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    compteur = compteur + 1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/train/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    print(#files)\n",
    "    temp2 = compteur2\n",
    "    temp3 = 0\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "\n",
    "        if (temp:size()[1]==3) then\n",
    "            compteur2 = compteur2 + 1\n",
    "            imagesAll[temp2 + i - temp3] = image.load(files[i]) \n",
    "            labelsAll[temp2 + i - temp3] = compteur\n",
    "            --print(temp2 + i, temp2 + i - temp3, dir, compteur, temp3)\n",
    "        else \n",
    "            temp3 = temp3 + 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    collectgarbage()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainData = {\n",
    "   data = torch.Tensor(1673, 3, 64, 64),\n",
    "   labels = torch.Tensor(1673),\n",
    "   size = function() return 1673 end\n",
    "\n",
    "}\n",
    "\n",
    "for i=1,1673 do\n",
    "   trainData.data[i] = imagesAll[i]\n",
    "   trainData.labels[i] = labelsAll[i]\n",
    "end\n",
    "\n",
    "--trainData.labels = trainData.labels + 1\n",
    "trainData.data = trainData.data:reshape(1673,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "bad argument #2 to '?' (out of range at /Users/danconstantini/torch/pkg/torch/generic/Tensor.c:888)\nstack traceback:\n\t[C]: at 0x059df0a0\n\t[C]: in function '__index'\n\t[string \"...\"]:4: in main chunk\n\t[C]: in function 'xpcall'\n\t...nconstantini/torch/install/share/lua/5.1/itorch/main.lua:179: in function <...nconstantini/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t...nconstantini/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...nstantini/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...nstantini/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...nstantini/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...nconstantini/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105659bb0",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "bad argument #2 to '?' (out of range at /Users/danconstantini/torch/pkg/torch/generic/Tensor.c:888)\nstack traceback:\n\t[C]: at 0x059df0a0\n\t[C]: in function '__index'\n\t[string \"...\"]:4: in main chunk\n\t[C]: in function 'xpcall'\n\t...nconstantini/torch/install/share/lua/5.1/itorch/main.lua:179: in function <...nconstantini/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t...nconstantini/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...nstantini/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...nstantini/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...nstantini/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...nconstantini/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105659bb0"
     ]
    }
   ],
   "source": [
    "\n",
    "temp=0\n",
    "for i=1,1672 do \n",
    "    if trainData.labels[i] == 0 then\n",
    "        temp= temp+1\n",
    "        print(i)\n",
    "    end\n",
    "end\n",
    "print (temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- preprocess/normalize train/test sets\n",
    "-- preprocess trainSet\n",
    "collectgarbage()\n",
    "\n",
    "\n",
    "\n",
    "normalization = nn.SpatialContrastiveNormalization(1, image.gaussian1D(7))\n",
    "\n",
    "for i = 1,1673 do\n",
    "   -- rgb -> yuv\n",
    "   local rgb = trainData.data[i]\n",
    "   local yuv = image.rgb2yuv(rgb)\n",
    "   -- normalize y locally:\n",
    "   yuv[1] = normalization(yuv[{{1}}])\n",
    "   trainData.data[i] = yuv\n",
    "end\n",
    "-- normalize u globally:\n",
    "mean_u = trainData.data[{ {},2,{},{} }]:mean()\n",
    "std_u = trainData.data[{ {},2,{},{} }]:std()\n",
    "trainData.data[{ {},2,{},{} }]:add(-mean_u)\n",
    "trainData.data[{ {},2,{},{} }]:div(-std_u)\n",
    "-- normalize v globally:\n",
    "mean_v = trainData.data[{ {},3,{},{} }]:mean()\n",
    "std_v = trainData.data[{ {},3,{},{} }]:std()\n",
    "trainData.data[{ {},3,{},{} }]:add(-mean_v)\n",
    "trainData.data[{ {},3,{},{} }]:div(-std_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collectgarbage()\n",
    "--trainData.data:mul(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- this matrix records the current confusion across classes\n",
    "confusion = optim.ConfusionMatrix(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- define training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- training function\n",
    "function train(dataset)\n",
    "   -- epoch tracker\n",
    "   epoch = epoch or 1\n",
    "\n",
    "   -- do one epoch\n",
    "   print('<trainer> on training set:')\n",
    "   print(\"<trainer> online epoch # \" .. epoch .. ' [batchSize = ' .. batchSize .. ']')\n",
    "   for t = 1,dataset:size(),batchSize do\n",
    "\n",
    "      -- create mini batch\n",
    "      local inputs = {}\n",
    "      local targets = {}\n",
    "      for i = t,math.min(t+batchSize-1,dataset:size()) do\n",
    "         -- load new sample\n",
    "         local input = dataset.data[i]\n",
    "         local target = dataset.labels[i]\n",
    "         table.insert(inputs, input)\n",
    "         table.insert(targets, target)\n",
    "      end\n",
    "      -- create closure to evaluate f(X) and df/dX\n",
    "      local feval = function(x)\n",
    "                       -- get new parameters\n",
    "                       if x ~= parameters then\n",
    "                          parameters:copy(x)\n",
    "                       end\n",
    "\n",
    "                       -- reset gradients\n",
    "                       gradParameters:zero()\n",
    "\n",
    "                       -- f is the average of all criterions\n",
    "                       local f = 0\n",
    "\n",
    "                       -- evaluate function for complete mini batch\n",
    "                       for i = 1,#inputs do\n",
    "                          -- estimate f\n",
    "                          local output = model:forward(inputs[i])\n",
    "                          local err = criterion:forward(output, targets[i])\n",
    "                          f = f + err\n",
    "\n",
    "                          -- estimate df/dW\n",
    "                          local df_do = criterion:backward(output, targets[i])\n",
    "                          model:backward(inputs[i], df_do)\n",
    "\n",
    "                          -- update confusion\n",
    "                          confusion:add(output, targets[i])                        \n",
    "                       end\n",
    "\n",
    "                       -- normalize gradients and f(X)\n",
    "                       gradParameters:div(#inputs)\n",
    "                       f = f/#inputs\n",
    "\n",
    "                       -- return f and df/dX\n",
    "                       return f,gradParameters\n",
    "                    end\n",
    "\n",
    "\n",
    "      config = config or {learningRate = 1e-3,\n",
    "              weightDecay = 0,\n",
    "                momentum = 0,\n",
    "              learningRateDecay = 5e-7}\n",
    "      optim.sgd(feval, parameters, config)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "   -- next epoch\n",
    "   epoch = epoch + 1\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- test function\n",
    "function test(dataset)\n",
    "\n",
    "   -- test over given dataset\n",
    "   print('<trainer> on testing Set:')\n",
    "   for t = 1,dataset:size() do\n",
    "      -- get new sample\n",
    "      local input = dataset.data[t]\n",
    "      local target = dataset.labels[t]\n",
    "\n",
    "      -- test sample\n",
    "      local pred = model:forward(input)\n",
    "      confusion:add(pred, target)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 3 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      47      16      15       6       8       7      22       9       6      20      25]   25.967% \t[class: bridge]\n",
       " [      13      52       4       1      11      11      11       4       7      20      18]   34.211% \t[class: building]\n",
       " [      16       8      11       3       6       3      10       5       7       4       8]   13.580% \t[class: city]\n",
       " [       1       1       0       1       1       1       4       1       0       3       3]   6.250% \t[class: eiffel_tower]\n",
       " [      14      23       9      12      60      10      32      14      17      13      14]   27.523% \t[class: elephant]\n",
       " [      11       4       5       1       0       2       4       3       2       8       4]   4.545% \t[class: landscape]\n",
       " [       6      15      10      13      19      14     155      15      19       5      12]   54.770% \t[class: lion]\n",
       " [      20      14      13      13      19      12      42      47      11       9      13]   22.066% \t[class: monkey]\n",
       " [       7      11      10       8      12       9      45       9      31       7      10]   19.497% \t[class: people]\n",
       " [      19      14       8       5       2       6       9       3       2      62      17]   42.177% \t[class: tower]\n",
       " [      14      11      11       5       4       6      28      11       9      22      58]]  32.402% \t[class: water]\n",
       " + average row correct: 25.726183842529% \n",
       " + average rowUcol correct (VOC measure): 15.318518402902% \n",
       " + global correct: 31.440526001195%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.15318518402902\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.25726183842529\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.31440526001195\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 4 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      68      13      11       5       6       4      24       5       5      19      21]   37.569% \t[class: bridge]\n",
       " [      11      65       2       1       9       6      10       4       5      24      15]   42.763% \t[class: building]\n",
       " [      16       6      18       2       5       2      10       5       6       4       7]   22.222% \t[class: city]\n",
       " [       1       1       0       1       1       0       4       1       1       3       3]   6.250% \t[class: eiffel_tower]\n",
       " [      12      21       6       7      78       8      35      13      17      10      11]   35.780% \t[class: elephant]\n",
       " [      10       6       5       1       1       3       4       1       2       8       3]   6.818% \t[class: landscape]\n",
       " [       6      10       6       7      17       8     185      14      16       4      10]   65.371% \t[class: lion]\n",
       " [      17      13      11      11      18      10      45      56      10       9      13]   26.291% \t[class: monkey]\n",
       " [       7      10       8       5      13       5      46       8      41       6      10]   25.786% \t[class: people]\n",
       " [      13      10       6       5       2       3       8       3       1      86      10]   58.503% \t[class: tower]\n",
       " [      11       8       7       5       5       4      30       7       8      20      74]]  41.341% \t[class: water]\n",
       " + average row correct: 33.517717434601% \n",
       " + average rowUcol correct (VOC measure): 20.823207404464% \n",
       " + global correct: 40.346682606097%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.20823207404464\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.33517717434601\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.40346682606097\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 5 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      80      11       9       5       4       4      24       5       4      19      16]   44.199% \t[class: bridge]\n",
       " [      11      80       2       1       8       8       9       4       3      19       7]   52.632% \t[class: building]\n",
       " [      17       4      27       1       2       1      11       4       6       3       5]   33.333% \t[class: city]\n",
       " [       2       1       0       1       1       0       2       1       1       4       3]   6.250% \t[class: eiffel_tower]\n",
       " [      12      20       4       6     100       8      29      11      10       8      10]   45.872% \t[class: elephant]\n",
       " [       8       8       4       1       0       7       4       0       1       8       3]   15.909% \t[class: landscape]\n",
       " [       6       9       4       6      13       5     203      11      14       3       9]   71.731% \t[class: lion]\n",
       " [      17      12       4       9      19       6      44      73      10       9      10]   34.272% \t[class: monkey]\n",
       " [       6       9       5       5      11       4      41       7      59       6       6]   37.107% \t[class: people]\n",
       " [      13      10       5       3       2       1       6       3       1      95       8]   64.626% \t[class: tower]\n",
       " [       9       7       4       4       4       4      29       6       7      19      86]]  48.045% \t[class: water]\n",
       " + average row correct: 41.270515864546% \n",
       " + average rowUcol correct (VOC measure): 27.110895920884% \n",
       " + global correct: 48.475791990436%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.27110895920884\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.41270515864546\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.48475791990436\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 6 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      93      10       8       2       4       3      23       5       4      14      15]   51.381% \t[class: bridge]\n",
       " [      11      89       2       1       7       5       9       4       2      16       6]   58.553% \t[class: building]\n",
       " [      16       2      33       1       2       0      11       4       5       2       5]   40.741% \t[class: city]\n",
       " [       1       0       0       1       1       0       3       1       1       5       3]   6.250% \t[class: eiffel_tower]\n",
       " [      10      16       3       6     113       7      26      11       9       9       8]   51.835% \t[class: elephant]\n",
       " [       7       7       3       1       0      11       5       0       0       8       2]   25.000% \t[class: landscape]\n",
       " [       7       8       4       5      11       2     216       9      12       3       6]   76.325% \t[class: lion]\n",
       " [      14       9       3       8      19       4      42      90       7       7      10]   42.254% \t[class: monkey]\n",
       " [       6       8       3       3      11       3      36       7      71       7       4]   44.654% \t[class: people]\n",
       " [      11      11       4       1       1       0       6       3       1     105       4]   71.429% \t[class: tower]\n",
       " [       9       5       4       2       3       4      28       4       6      15      99]]  55.307% \t[class: water]\n",
       " + average row correct: 47.611635110595% \n",
       " + average rowUcol correct (VOC measure): 32.793413424356% \n",
       " + global correct: 55.050806933652%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.32793413424356\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.47611635110595\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.55050806933652\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 7 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     105       7       7       1       3       2      22       4       4      14      12]   58.011% \t[class: bridge]\n",
       " [       8     100       2       1       4       4       9       4       2      15       3]   65.789% \t[class: building]\n",
       " [      15       2      42       1       1       0       8       3       3       2       4]   51.852% \t[class: city]\n",
       " [       1       0       0       1       1       0       3       1       1       5       3]   6.250% \t[class: eiffel_tower]\n",
       " [       9      13       2       5     134       5      21       9       7       7       6]   61.468% \t[class: elephant]\n",
       " [       5       5       2       0       0      19       4       0       0       7       2]   43.182% \t[class: landscape]\n",
       " [       7       9       1       3       9       2     228       6       8       3       7]   80.565% \t[class: lion]\n",
       " [      13       6       2       5      17       4      35     112       6       6       7]   52.582% \t[class: monkey]\n",
       " [       4      10       3       1       8       1      33       6      86       5       2]   54.088% \t[class: people]\n",
       " [       9       9       2       0       1       0       7       3       1     113       2]   76.871% \t[class: tower]\n",
       " [      10       4       3       2       3       2      27       2       4      12     110]]  61.453% \t[class: water]\n",
       " + average row correct: 55.646447160027% \n",
       " + average rowUcol correct (VOC measure): 40.687937645072% \n",
       " + global correct: 62.761506276151%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.40687937645072\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.55646447160027\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.62761506276151\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 8 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     116       6       6       0       3       1      18       4       4      13      10]   64.088% \t[class: bridge]\n",
       " [       7     109       1       1       5       2       8       3       2      11       3]   71.711% \t[class: building]\n",
       " [      13       2      47       1       1       0       7       3       3       2       2]   58.025% \t[class: city]\n",
       " [       1       0       0       2       0       0       3       1       1       5       3]   12.500% \t[class: eiffel_tower]\n",
       " [       5       9       0       2     163       2      16       6       7       5       3]   74.771% \t[class: elephant]\n",
       " [       5       4       2       0       0      23       4       0       0       5       1]   52.273% \t[class: landscape]\n",
       " [       5      10       1       2       7       1     236       5       7       3       6]   83.392% \t[class: lion]\n",
       " [      12       5       2       4      15       3      29     125       7       4       7]   58.685% \t[class: monkey]\n",
       " [       3       9       1       0       7       1      26       4     102       4       2]   64.151% \t[class: people]\n",
       " [       8       7       1       0       1       0       6       2       1     119       2]   80.952% \t[class: tower]\n",
       " [      10       4       1       1       2       0      25       2       2      11     121]]  67.598% \t[class: water]\n",
       " + average row correct: 62.558704072779% \n",
       " + average rowUcol correct (VOC measure): 48.426115377383% \n",
       " + global correct: 69.515839808727%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.48426115377383\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.62558704072779\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.69515839808727\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 9 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     131       4       4       0       2       1      15       3       4      11       6]   72.376% \t[class: bridge]\n",
       " [       7     121       1       0       5       0       4       3       0       8       3]   79.605% \t[class: building]\n",
       " [      10       2      57       0       0       0       4       3       3       1       1]   70.370% \t[class: city]\n",
       " [       1       0       0       2       0       0       2       2       1       5       3]   12.500% \t[class: eiffel_tower]\n",
       " [       4       9       0       1     171       2      15       3       5       5       3]   78.440% \t[class: elephant]\n",
       " [       5       3       2       0       0      26       3       0       0       4       1]   59.091% \t[class: landscape]\n",
       " [       4      11       0       0       7       0     245       3       6       3       4]   86.572% \t[class: lion]\n",
       " [      12       5       1       3      13       2      22     140       7       3       5]   65.728% \t[class: monkey]\n",
       " [       3       9       1       0       4       0      21       4     112       3       2]   70.440% \t[class: people]\n",
       " [       6       5       1       0       1       0       6       2       1     123       2]   83.673% \t[class: tower]\n",
       " [       7       3       1       1       1       0      23       2       2      11     128]]  71.508% \t[class: water]\n",
       " + average row correct: 68.209530548616% \n",
       " + average rowUcol correct (VOC measure): 55.386556346308% \n",
       " + global correct: 75.0747160789%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.55386556346308\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.68209530548616\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.750747160789\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 10 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     137       4       2       0       2       1      14       2       4      10       5]   75.691% \t[class: bridge]\n",
       " [       7     125       0       0       5       0       3       2       0       7       3]   82.237% \t[class: building]\n",
       " [       8       3      61       0       0       0       3       3       2       1       0]   75.309% \t[class: city]\n",
       " [       1       0       0       2       0       0       2       2       1       5       3]   12.500% \t[class: eiffel_tower]\n",
       " [       4       5       0       1     187       0      13       2       3       2       1]   85.780% \t[class: elephant]\n",
       " [       5       3       2       0       0      27       3       0       0       3       1]   61.364% \t[class: landscape]\n",
       " [       3      10       0       0       6       0     250       3       6       3       2]   88.339% \t[class: lion]\n",
       " [      12       5       1       2      10       1      18     154       5       1       4]   72.300% \t[class: monkey]\n",
       " [       2       9       1       0       1       0      17       4     120       3       2]   75.472% \t[class: people]\n",
       " [       3       5       1       0       2       0       5       1       2     126       2]   85.714% \t[class: tower]\n",
       " [       5       3       1       1       1       0      21       1       2       9     135]]  75.419% \t[class: water]\n",
       " + average row correct: 71.829475056041% \n",
       " + average rowUcol correct (VOC measure): 60.476367920637% \n",
       " + global correct: 79.13927077107%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.60476367920637\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.71829475056041\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.7913927077107\n",
       "}\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 11 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     144       4       2       0       2       0      12       2       4       7       4]   79.558% \t[class: bridge]\n",
       " [       7     128       0       0       4       0       3       2       0       6       2]   84.211% \t[class: building]\n",
       " [       7       3      64       0       0       0       2       2       2       1       0]   79.012% \t[class: city]\n",
       " [       1       0       0       3       0       0       2       1       1       5       3]   18.750% \t[class: eiffel_tower]\n",
       " [       2       5       0       1     192       0      10       2       3       2       1]   88.073% \t[class: elephant]\n",
       " [       4       2       2       0       0      32       2       0       0       1       1]   72.727% \t[class: landscape]\n",
       " [       3      10       0       0       5       0     253       2       5       3       2]   89.399% \t[class: lion]\n",
       " [       8       4       1       1       9       1      15     168       4       0       2]   78.873% \t[class: monkey]\n",
       " [       2       7       1       0       1       0      14       2     127       4       1]   79.874% \t[class: people]\n",
       " [       2       5       1       0       2       0       5       1       2     127       2]   86.395% \t[class: tower]\n",
       " [       2       3       1       1       1       0      18       1       2       6     144]]  80.447% \t[class: water]\n",
       " + average row correct: 76.119981028817% \n",
       " + average rowUcol correct (VOC measure): 65.910070050846% \n",
       " + global correct: 82.606096832038%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.65910070050846\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.76119981028817\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.82606096832038\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 12 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     153       3       2       0       1       0       9       2       3       6       2]   84.530% \t[class: bridge]\n",
       " [       6     132       0       0       4       0       3       2       0       4       1]   86.842% \t[class: building]\n",
       " [       5       3      66       0       0       0       2       2       2       1       0]   81.481% \t[class: city]\n",
       " [       1       0       0       7       0       0       1       1       0       5       1]   43.750% \t[class: eiffel_tower]\n",
       " [       1       5       0       0     198       0       7       2       2       2       1]   90.826% \t[class: elephant]\n",
       " [       3       2       1       0       0      35       2       0       0       0       1]   79.545% \t[class: landscape]\n",
       " [       3       5       0       0       4       0     261       1       4       3       2]   92.226% \t[class: lion]\n",
       " [       7       3       0       1       7       0      11     179       3       1       1]   84.038% \t[class: monkey]\n",
       " [       2       5       0       0       1       0      10       2     135       3       1]   84.906% \t[class: people]\n",
       " [       1       3       1       0       2       0       4       1       2     131       2]   89.116% \t[class: tower]\n",
       " [       2       2       1       1       1       0      17       1       2       5     147]]  82.123% \t[class: water]\n",
       " + average row correct: 81.762094389309% \n",
       " + average rowUcol correct (VOC measure): 73.050757971677% \n",
       " + global correct: 86.312014345487%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.73050757971677\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.81762094389309\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.86312014345487\n",
       "}\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "while i<10 do\n",
    "train(trainData)\n",
    "i=i+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save('model1layer.net',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15544034851502\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.16365542069888\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save('model1.net', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trainer> on testing Set:\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      24       8       8       5       2       2       8       6      24      16]   23.301% \t[class: airplane]\n",
       " [       4      58       1       4       0       0       7       4       1      10]   65.169% \t[class: automobile]\n",
       " [       5       5      28      11       8       4      20       7       8       4]   28.000% \t[class: bird]\n",
       " [       3       7      11      30       3       6      30       3       5       5]   29.126% \t[class: cat]\n",
       " [       4       1      10       8      12       1      37      11       4       2]   13.333% \t[class: deer]\n",
       " [       1       5       9      25       4      10      20       4       3       5]   11.628% \t[class: dog]\n",
       " [       0       1       3      20       3       5      71       2       3       4]   63.393% \t[class: frog]\n",
       " [       5       3       7       8       7       6      13      47       2       4]   46.078% \t[class: horse]\n",
       " [      22       9       4       6       2       0       1       4      51       7]   48.113% \t[class: ship]\n",
       " [       9      38       3       7       2       3       5       7       4      31]]  28.440% \t[class: truck]\n",
       " + average row correct: 35.658183768392% \n",
       " + average rowUcol correct (VOC measure): 21.221470534801% \n",
       " + global correct: 36.2%\n",
       "{\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : FloatTensor - size: 10x10\n",
       "  averageUnionValid : 0.21221470534801\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.35658183768392\n",
       "  classes : \n",
       "    {\n",
       "      1 : airplane\n",
       "      2 : automobile\n",
       "      3 : bird\n",
       "      4 : cat\n",
       "      5 : deer\n",
       "      6 : dog\n",
       "      7 : frog\n",
       "      8 : horse\n",
       "      9 : ship\n",
       "      10 : truck\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 0.362\n",
       "}\n",
       "0.2776620388031\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "test(testData)\n",
    "print (timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9\t\n"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.labels[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: airplane]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: automobile]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: bird]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: cat]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: deer]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: dog]\n",
       " [       0       0       0       0       0       0       1       0       0       0]   100.000% \t[class: frog]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: horse]\n",
       " [       0       0       0       0       0       0       0       0       0       0]   nan% \t[class: ship]\n",
       " [       0       0       0       0       0       0       0       0       0       0]]  nan% \t[class: truck]\n",
       " + average row correct: 100% \n",
       " + average rowUcol correct (VOC measure): 100% \n",
       " + global correct: 100%\n",
       "{\n",
       "  valids : FloatTensor - size: 10\n",
       "  mat : FloatTensor - size: 10x10\n",
       "  averageUnionValid : 1\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 1\n",
       "  classes : \n",
       "    {\n",
       "      1 : airplane\n",
       "      2 : automobile\n",
       "      3 : bird\n",
       "      4 : cat\n",
       "      5 : deer\n",
       "      6 : dog\n",
       "      7 : frog\n",
       "      8 : horse\n",
       "      9 : ship\n",
       "      10 : truck\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 10\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 10\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 10\n",
       "  totalValid : 1\n",
       "}\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "j=50\n",
    "confusion:zero()\n",
    "\n",
    "\n",
    "itorch.image(testData.data[j])\n",
    "inp= testData.data[j]\n",
    "tar= testData.labels[j]\n",
    "\n",
    "pred = model:forward(inp)\n",
    "confusion:add(pred, tar)\n",
    "print(confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1657\n",
       "-2.3892\n",
       "-2.5634\n",
       "-4.5198\n",
       "-4.0242\n",
       "-5.7736\n",
       "-6.7106\n",
       "-5.2705\n",
       "-0.9884\n",
       "-2.2155\n",
       "[torch.DoubleTensor of dimension 10]\n",
       "\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"for (i=1,100 and i~=5) do...\"]:1: '<name>' expected near '('",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"for (i=1,100 and i~=5) do...\"]:1: '<name>' expected near '('"
     ]
    }
   ],
   "source": [
    "for i=1,100 and i~=5) do\n",
    "    print(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1~=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
