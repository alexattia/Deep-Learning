{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "Dan Constantini, Tom Hayat et Alexandre Attia\n",
    "This script loads 11 data class from imagenet and sort the files according to their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total\t1861\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'\n",
    "require 'xlua'\n",
    "require 'image'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'cunn'\n",
    "\n",
    "\n",
    "--classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "total = 0\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, 1)\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    total = total + #files\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print('total', total)\n",
    "\n",
    "imagesAll = torch.Tensor(total,3,64,64) \n",
    "labelsAll = torch.Tensor(total)\n",
    "compteur = 0\n",
    "NumberOfImages = {0}\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    compteur = compteur +1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/train/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    lastElement = NumberOfImages[#NumberOfImages]\n",
    "    table.insert(NumberOfImages, #files + lastElement)\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "        temp2 = torch.Tensor(3,64,64) \n",
    "        if (temp:size()[1]==1) then\n",
    "            temp2[{{1},{},{}}] = temp\n",
    "            temp2[{{2},{},{}}] = temp\n",
    "            temp2[{{3},{},{}}] = temp\n",
    "        else \n",
    "            temp2 = temp\n",
    "        end\n",
    "        imagesAll[i+lastElement] = temp2 \n",
    "        labelsAll[i+lastElement] = compteur\n",
    "    end\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "\n",
    "-- Nombre d'images courleurs: 1683 \n",
    "trainData = {\n",
    "    data = torch.Tensor(total, 3, 64, 64),\n",
    "    labels = torch.Tensor(total),\n",
    "    size = function() return total end,\n",
    "\n",
    "}\n",
    "--[[create test set:\n",
    "testData = {\n",
    "      data = torch.Tensor(tesize, 1, 32, 32),\n",
    "      labels = torch.Tensor(tesize),\n",
    "      size = function() return tesize end\n",
    "   }\n",
    "]]--\n",
    "\n",
    "for i=1,total do\n",
    "   trainData.data[i] = imagesAll[i]\n",
    "   trainData.labels[i] = labelsAll[i]\n",
    "end\n",
    "--for i=trsize+1,tesize+trsize do\n",
    "   --testData.data[i-trsize] = imagesAll[labelsShuffle[i]][1]:clone()\n",
    "   --testData.labels[i-trsize] = labelsAll[labelsShuffle[i]]\n",
    "--end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : DoubleTensor - size: 1861x3x64x64\n",
       "  size : function: 0x06c65600\n",
       "  labels : DoubleTensor - size: 1861\n",
       "}\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--for i=1,total do \n",
    "    --itorch.image(imagesAll[i])\n",
    "    --print(labelsAll[i])\n",
    "--end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: colorspace RGB -> YUV\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize each feature (channel) globally\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize all three channels locally\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> verify statistics\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, y-channel, mean: -0.01881966926504\t\n",
       "training data, y-channel, standard deviation: 0.86958206694476\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, u-channel, mean: 0.01750703263677\t\n",
       "training data, u-channel, standard deviation: 0.8532538826994\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, v-channel, mean: -0.015721198933372\t\n",
       "training data, v-channel, standard deviation: 0.84829254696119\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Convert all images to YUV\n",
    "collectgarbage()\n",
    "print '==> preprocessing data: colorspace RGB -> YUV'\n",
    "for i = 1,total do\n",
    "   trainData.data[i] = image.rgb2yuv(trainData.data[i])\n",
    "end\n",
    "--for i = 1,325 do\n",
    "  -- testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "--end\n",
    "-- Name channels for convenience\n",
    "channels = {'y','u','v'}\n",
    "\n",
    "-- Normalize each channel, and store mean/std\n",
    "-- per channel. These values are important, as they are part of\n",
    "-- the trainable parameters. At test time, test data will be normalized\n",
    "-- using these values.\n",
    "print '==> preprocessing data: normalize each feature (channel) globally'\n",
    "mean = {}\n",
    "std = {}\n",
    "for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   mean[i] = trainData.data[{ {},i,{},{} }]:mean()\n",
    "   std[i] = trainData.data[{ {},i,{},{} }]:std()\n",
    "   trainData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   trainData.data[{ {},i,{},{} }]:div(std[i])\n",
    "end\n",
    "\n",
    "-- Normalize test data, using the training means/stds\n",
    "--for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   --testData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   --testData.data[{ {},i,{},{} }]:div(std[i])\n",
    "--end\n",
    "-- Local normalization\n",
    "print '==> preprocessing data: normalize all three channels locally'\n",
    "\n",
    "-- Define the normalization neighborhood:\n",
    "neighborhood = image.gaussian1D(13)\n",
    "\n",
    "-- Define our local normalization operator (It is an actual nn module, \n",
    "-- which could be inserted into a trainable model):\n",
    "normalization = nn.SpatialContrastiveNormalization(1, neighborhood)\n",
    "\n",
    "-- Normalize all channels locally:\n",
    "for c in ipairs(channels) do\n",
    "   for i = 1,total do\n",
    "      trainData.data[{ i,{c},{},{} }] = normalization:forward(trainData.data[{ i,{c},{},{} }])\n",
    "   end\n",
    "   --for i = 1,325 do\n",
    "      --testData.data[{ i,{c},{},{} }] = normalization:forward(testData.data[{ i,{c},{},{} }])\n",
    "   --end\n",
    "end\n",
    "\n",
    "print '==> verify statistics'\n",
    "for i,channel in ipairs(channels) do\n",
    "   trainMean = trainData.data[{ {},i }]:mean()\n",
    "   trainStd = trainData.data[{ {},i }]:std()\n",
    "\n",
    "   --testMean = testData.data[{ {},i }]:mean()\n",
    "   --testStd = testData.data[{ {},i }]:std()\n",
    "\n",
    "   print('training data, '..channel..'-channel, mean: ' .. trainMean)\n",
    "   print('training data, '..channel..'-channel, standard deviation: ' .. trainStd)\n",
    "\n",
    "   --print('test data, '..channel..'-channel, mean: ' .. testMean)\n",
    "   --print('test data, '..channel..'-channel, standard deviation: ' .. testStd)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> vizualisation du modèle\t\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]\n",
       "  (1): nn.SpatialConvolutionMM(3 -> 64, 5x5)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (4): nn.SpatialConvolutionMM(64 -> 64, 5x5)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (7): nn.View(10816)\n",
       "  (8): nn.Linear(10816 -> 11)\n",
       "  (9): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nn.ClassNLLCriterion\n",
       "{\n",
       "  sizeAverage : true\n",
       "  output : 0\n",
       "  gradInput : DoubleTensor - empty\n",
       "  output_tensor : DoubleTensor - size: 1\n",
       "  target : LongTensor - size: 1\n",
       "  total_weight_tensor : DoubleTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- define model to train\n",
    "classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "-- define model to train\n",
    "\n",
    "model = nn.Sequential()\n",
    " --stage 1 : mean+std normalization -> filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(3,64,5,5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "-- stage 2 : filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(64,64,5,5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "-- stage 3 : standard 2-layer neural network\n",
    "model:add(nn.View(64*13*13))\n",
    "model:add(nn.Linear(64*13*13, #classes))\n",
    "--model:add(nn.ReLU())\n",
    "--model:add(nn.Linear(128,#classes))\n",
    "model:add(nn.LogSoftMax())\n",
    "\n",
    "print '==> vizualisation du modèle'\n",
    "print(model:__tostring())\n",
    "-- retrieve parameters and gradients. this helps us to use the optim package\n",
    "parameters,gradParameters = model:getParameters()\n",
    "-- loss function: negative log-likelihood\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "print (criterion)\n",
    "batchSize = 64 -- sets the mini-Batch size\n",
    "-- this matrix records the current confusion across classes\n",
    "confusion = optim.ConfusionMatrix(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "\n",
    "model = nn.Sequential()\n",
    "model:add(nn.Reshape(3*64*64))\n",
    "model:add(nn.Linear(3*64*64,#classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other model, test with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> vizualisation du modèle\t\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> output]\n",
       "  (1): nn.Sequential {\n",
       "    [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]\n",
       "    (1): nn.SpatialConvolutionMM(3 -> 32, 5x5)\n",
       "    (2): nn.Threshold\n",
       "    (3): nn.SpatialMaxPooling(4x4, 4,4)\n",
       "    (4): nn.SpatialConvolutionMM(32 -> 64, 7x7)\n",
       "    (5): nn.Threshold\n",
       "  }\n",
       "  (2): nn.Sequential {\n",
       "    [input -> (1) -> (2) -> (3) -> output]\n",
       "    (1): nn.Reshape(64)\n",
       "    (2): nn.Linear(64 -> 2)\n",
       "    (3): nn.LogSoftMax\n",
       "  }\n",
       "}\t\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nn.ClassNLLCriterion\n",
       "{\n",
       "  sizeAverage : true\n",
       "  output : 0\n",
       "  gradInput : DoubleTensor - empty\n",
       "  output_tensor : DoubleTensor - size: 1\n",
       "  target : LongTensor - size: 1\n",
       "  total_weight_tensor : DoubleTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "local noutputs = 11\n",
    "\n",
    "-- input dimensions: faces!\n",
    "local nfeats = 3\n",
    "local width = 64\n",
    "local height = 64\n",
    "\n",
    "-- hidden units, filter sizes (for ConvNet only):\n",
    "local nstates = {32,64}\n",
    "local filtsize = {5, 7}\n",
    "local poolsize = 4\n",
    "\n",
    "local CNN = nn.Sequential()\n",
    "\n",
    "-- stage 1: conv+max\n",
    "CNN:add(nn.SpatialConvolutionMM(nfeats, nstates[1], filtsize[1], filtsize[1]))\n",
    "CNN:add(nn.Threshold())\n",
    "CNN:add(nn.SpatialMaxPooling(poolsize,poolsize,poolsize,poolsize))\n",
    "\n",
    "-- stage 2: conv+max\n",
    "CNN:add(nn.SpatialConvolutionMM(nstates[1], nstates[2], filtsize[2], filtsize[2]))\n",
    "CNN:add(nn.Threshold())\n",
    "\n",
    "local classifier = nn.Sequential()\n",
    "-- stage 3: linear\n",
    "classifier:add(nn.Reshape(nstates[2]))\n",
    "classifier:add(nn.Linear(nstates[2], 2))\n",
    "\n",
    "-- stage 4 : log probabilities\n",
    "classifier:add(nn.LogSoftMax())\n",
    "local model = nn.Sequential()\n",
    "model:add(CNN)\n",
    "model:add(classifier)\n",
    "\n",
    "print '==> vizualisation du modèle'\n",
    "print(model:__tostring())\n",
    "-- retrieve parameters and gradients. this helps us to use the optim package\n",
    "parameters,gradParameters = model:getParameters()\n",
    "-- loss function: negative log-likelihood\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "print (criterion)\n",
    "batchSize = 64 -- sets the mini-Batch size\n",
    "-- this matrix records the current confusion across classes\n",
    "confusion = optim.ConfusionMatrix(classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--passage en CUDA\n",
    "model = model:cuda()\n",
    "criterion = criterion:cuda()\n",
    "trainData.data = trainData.data:cuda()\n",
    "trainData.labels = trainData.labels:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- training function\n",
    "collectgarbage()\n",
    "function train(dataset)\n",
    "   -- epoch tracker\n",
    "   epoch = epoch or 1\n",
    "\n",
    "   -- do one epoch\n",
    "   print('<trainer> on training set:')\n",
    "   print(\"<trainer> online epoch # \" .. epoch .. ' [batchSize = ' .. batchSize .. ']')\n",
    "   for t = 1,dataset:size(),batchSize do\n",
    "\n",
    "      -- create mini batch\n",
    "      local inputs = {}\n",
    "      local targets = {}\n",
    "      for i = t,math.min(t+batchSize-1,dataset:size()) do\n",
    "         -- load new sample\n",
    "         local input = dataset.data[i]\n",
    "         local target = dataset.labels[i]\n",
    "         table.insert(inputs, input)\n",
    "         table.insert(targets, target)\n",
    "      end\n",
    "      -- create closure to evaluate f(X) and df/dX\n",
    "      local feval = function(x)\n",
    "                       -- get new parameters\n",
    "                       if x ~= parameters then\n",
    "                          parameters:copy(x)\n",
    "                       end\n",
    "\n",
    "                       -- reset gradients\n",
    "                       gradParameters:zero()\n",
    "\n",
    "                       -- f is the average of all criterions\n",
    "                       local f = 0\n",
    "\n",
    "                       -- evaluate function for complete mini batch\n",
    "                       for i = 1,#inputs do\n",
    "                          -- estimate f\n",
    "                          local output = model:forward(inputs[i])\n",
    "                          local err = criterion:forward(output, targets[i])\n",
    "                          f = f + err\n",
    "\n",
    "                          -- estimate df/dW\n",
    "                          local df_do = criterion:backward(output, targets[i])\n",
    "                          model:backward(inputs[i], df_do)\n",
    "\n",
    "                          -- update confusion\n",
    "                          confusion:add(output, targets[i])                        \n",
    "                       end\n",
    "\n",
    "                       -- normalize gradients and f(X)\n",
    "                       gradParameters:div(#inputs)\n",
    "                       f = f/#inputs\n",
    "\n",
    "                       -- return f and df/dX\n",
    "                       return f,gradParameters\n",
    "                    end\n",
    "\n",
    "\n",
    "      config = config or {learningRate = 1e-3,\n",
    "              weightDecay = 0,\n",
    "                momentum = 0,\n",
    "              learningRateDecay = 5e-7}\n",
    "      optim.sgd(feval, parameters, config)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "   -- next epoch\n",
    "   epoch = epoch + 1\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "0\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "32\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "64\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "96\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "107\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "139\t\n",
       "{\n",
       "}\n",
       "171\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "203\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "235\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "267\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "299\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "total\t331\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: colorspace RGB -> YUV\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize each feature (channel) globally\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize all three channels locally\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> verify statistics\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, y-channel, mean: -0.017539901252773\t\n",
       "test data, y-channel, standard deviation: 0.87259989006525\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, u-channel, mean: 0.018839901418081\t\n",
       "test data, u-channel, standard deviation: 0.86362135210153\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, v-channel, mean: -0.017297258674264\t\n",
       "test data, v-channel, standard deviation: 0.85897246440964\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "totaltest = 0\n",
    "for dir in paths.iterdirs(\"./dataset/val/\") do\n",
    "    files = {}\n",
    "    print(files)\n",
    "    for file in paths.files(paths.concat('./dataset/val/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, 1)\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "    print(totaltest)\n",
    "    totaltest = totaltest + #files\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print('total', totaltest)\n",
    "\n",
    "imagesAll = torch.Tensor(totaltest,3,64,64) \n",
    "labelsAll = torch.Tensor(totaltest)\n",
    "compteur = 0\n",
    "NumberOfImages = {0}\n",
    "for dir in paths.iterdirs(\"./dataset/val/\") do\n",
    "    compteur = compteur +1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/val/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/val/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    lastElement = NumberOfImages[#NumberOfImages]\n",
    "    table.insert(NumberOfImages, #files + lastElement)\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "        temp2 = torch.Tensor(3,64,64) \n",
    "        if (temp:size()[1]==1) then\n",
    "            temp2[{{1},{},{}}] = temp\n",
    "            temp2[{{2},{},{}}] = temp\n",
    "            temp2[{{3},{},{}}] = temp\n",
    "        else \n",
    "            temp2 = temp\n",
    "        end\n",
    "        imagesAll[i+lastElement] = temp2 \n",
    "        labelsAll[i+lastElement] = compteur\n",
    "    end\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "\n",
    "-- Nombre d'images courleurs: 1683 \n",
    "testData = {\n",
    "    data = torch.Tensor(totaltest, 3, 64, 64),\n",
    "    labels = torch.Tensor(totaltest),\n",
    "    size = function() return totaltest end,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "for i=1,totaltest do\n",
    "   testData.data[i] = imagesAll[i]\n",
    "   testData.labels[i] = labelsAll[i]\n",
    "end\n",
    "\n",
    "-- Convert all images to YUV\n",
    "print '==> preprocessing data: colorspace RGB -> YUV'\n",
    "for i = 1,totaltest do\n",
    "   testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "end\n",
    "--for i = 1,325 do\n",
    "  -- testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "--end\n",
    "-- Name channels for convenience\n",
    "channels = {'y','u','v'}\n",
    "\n",
    "-- Normalize each channel, and store mean/std\n",
    "-- per channel. These values are important, as they are part of\n",
    "-- the trainable parameters. At test time, test data will be normalized\n",
    "-- using these values.\n",
    "print '==> preprocessing data: normalize each feature (channel) globally'\n",
    "--mean = {}\n",
    "--std = {}\n",
    "for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   testData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   testData.data[{ {},i,{},{} }]:div(std[i])\n",
    "end\n",
    "\n",
    "-- Local normalization\n",
    "print '==> preprocessing data: normalize all three channels locally'\n",
    "\n",
    "-- Define the normalization neighborhood:\n",
    "neighborhood = image.gaussian1D(13)\n",
    "\n",
    "-- Define our local normalization operator (It is an actual nn module, \n",
    "-- which could be inserted into a trainable model):\n",
    "normalization = nn.SpatialContrastiveNormalization(1, neighborhood)\n",
    "\n",
    "-- Normalize all channels locally:\n",
    "for c in ipairs(channels) do\n",
    "\n",
    "   for i = 1,totaltest do\n",
    "      testData.data[{ i,{c},{},{} }] = normalization:forward(testData.data[{ i,{c},{},{} }])\n",
    "   end\n",
    "end\n",
    "\n",
    "print '==> verify statistics'\n",
    "for i,channel in ipairs(channels) do\n",
    "\n",
    "   testMean = testData.data[{ {},i }]:mean()\n",
    "   testStd = testData.data[{ {},i }]:std()\n",
    "\n",
    "\n",
    "   print('test data, '..channel..'-channel, mean: ' .. testMean)\n",
    "   print('test data, '..channel..'-channel, standard deviation: ' .. testStd)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- test function\n",
    "function test(dataset)\n",
    "\n",
    "   -- test over given dataset\n",
    "   print('<trainer> on testing Set:')\n",
    "   for t = 1,dataset:size() do\n",
    "      -- get new sample\n",
    "      local input = dataset.data[t]\n",
    "      local target = dataset.labels[t]\n",
    "\n",
    "      -- test sample\n",
    "      local pred = model:forward(input)\n",
    "      confusion:add(pred, target)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 13 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 14 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 15 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 16 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       " "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "     5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 17 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 18 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 19 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 20 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       " "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "     5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 21 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 22 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[      13      10      13      15      16      16      19      23      16      21      23]   7.027% \t[class: bridge]\n",
       " [      16      19       8       6      19      21      14       8      17      22       7]   12.102% \t[class: building]\n",
       " [      10       8       9      10       8       4       8       6       5       6      11]   10.588% \t[class: city]\n",
       " [      15      10      13      16      20      17      14      15      11      14      12]   10.191% \t[class: eiffel_tower]\n",
       " [      22      21      26      26      20      20      18      15      21      16      18]   8.969% \t[class: elephant]\n",
       " [      10       2       9       2       4       5       2       4       0       3       3]   11.364% \t[class: landscape]\n",
       " [      28      24      24      20      25      21      30      33      25      26      32]   10.417% \t[class: lion]\n",
       " [      19      18      15      22      21      14      20      22      23      20      21]   10.233% \t[class: monkey]\n",
       " [      17      10      10      21      13      15       8      18      20      18      14]   12.195% \t[class: people]\n",
       " [      12       9      16      13      16       4      14      16      22      19      12]   12.418% \t[class: tower]\n",
       " [      17      15      17      23      19      18      12      19      22      14      14]]  7.368% \t[class: water]\n",
       " + average row correct: 10.261051898653% \n",
       " + average rowUcol correct (VOC measure): 5.133412219584% \n",
       " + global correct: 10.048361096185%\n",
       "{\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.05133412219584\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.10261051898653\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10048361096185\n",
       "}\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "while i<10 do\n",
    "    train(trainData)\n",
    "    test(testData)\n",
    "    i=i+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
