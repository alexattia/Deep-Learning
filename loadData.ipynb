{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "Dan Constantini, Tom Hayat et Alexandre Attia\n",
    "This script loads 11 data class from imagenet and sort the files according to their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'xlua'\n",
    "require 'image'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "\n",
    "\n",
    "--classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "total = 0\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, 1)\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    total = total + #files\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print('total', total)\n",
    "\n",
    "imagesAll = torch.Tensor(total,3,64,64) \n",
    "labelsAll = torch.Tensor(total)\n",
    "compteur = 0\n",
    "NumberOfImages = {0}\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    compteur = compteur +1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/train/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    lastElement = NumberOfImages[#NumberOfImages]\n",
    "    table.insert(NumberOfImages, #files + lastElement)\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "        temp2 = torch.Tensor(3,64,64) \n",
    "        if (temp:size()[1]==1) then\n",
    "            temp2[{{1},{},{}}] = temp\n",
    "            temp2[{{2},{},{}}] = temp\n",
    "            temp2[{{3},{},{}}] = temp\n",
    "        else \n",
    "            temp2 = temp\n",
    "        end\n",
    "        imagesAll[i+lastElement] = temp2 \n",
    "        labelsAll[i+lastElement] = compteur\n",
    "    end\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "\n",
    "-- Nombre d'images courleurs: 1683 \n",
    "trainData = {\n",
    "    data = torch.Tensor(total, 3, 64, 64),\n",
    "    labels = torch.Tensor(total),\n",
    "    size = function() return total end,\n",
    "\n",
    "}\n",
    "--[[create test set:\n",
    "testData = {\n",
    "      data = torch.Tensor(tesize, 1, 32, 32),\n",
    "      labels = torch.Tensor(tesize),\n",
    "      size = function() return tesize end\n",
    "   }\n",
    "]]--\n",
    "\n",
    "for i=1,total do\n",
    "   trainData.data[i] = imagesAll[i]\n",
    "   trainData.labels[i] = labelsAll[i]\n",
    "end\n",
    "--for i=trsize+1,tesize+trsize do\n",
    "   --testData.data[i-trsize] = imagesAll[labelsShuffle[i]][1]:clone()\n",
    "   --testData.labels[i-trsize] = labelsAll[labelsShuffle[i]]\n",
    "--end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : DoubleTensor - size: 1718x3x64x64\n",
       "  size : function: 0x10532ae0\n",
       "  labels : DoubleTensor - size: 1718\n",
       "}\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--for i=1,total do \n",
    "    --itorch.image(imagesAll[i])\n",
    "    --print(labelsAll[i])\n",
    "--end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problème :</b> à partir de l'image 288, les images sont entierement noirs et le label est nul. Je pense qu'il y a un probleme avec le `if (temp:size()[1]==3) then` ! En fait c'est avant je crois, quand on print le nombre de files ils en mettent que 190 .. --> J'ai compris on a un probleme dans la boucle, en fait, elle repart de 0 à chaque fois pour imageAll, donc à chaque fois qu'on parcourt un repertory d'images on réécrit sur les images anciennes (la liste `files` est temporaire. Le nombres d'images dans imagesAll est donc 288 car le nombre maximal d'images des dossiers du dataset est 288. \n",
    "\n",
    "``for i=1,(#files) do\n",
    "        print('dossier : ', compteur)\n",
    "        print(#files)\n",
    "        temp = image.load(files[i])\n",
    "        --print(files[i])\n",
    "        if (temp:size()[1]==3) then\n",
    "            imagesAll[i] = image.load(files[i]) \n",
    "            labelsAll[i] = compteur\n",
    "        end\n",
    "    end\n",
    "``\n",
    "\n",
    "Est ce que ce code là on le sort pas de la grosse boucle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: colorspace RGB -> YUV\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize each feature (channel) globally\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize all three channels locally\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> verify statistics\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, y-channel, mean: -0.01230503978826\t\n",
       "training data, y-channel, standard deviation: 0.87869466420519\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, u-channel, mean: 0.02077713221656\t\n",
       "training data, u-channel, standard deviation: 0.86500893791238\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, v-channel, mean: -0.022945227037842\t\n",
       "training data, v-channel, standard deviation: 0.86984177871383\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Convert all images to YUV\n",
    "print '==> preprocessing data: colorspace RGB -> YUV'\n",
    "for i = 1,total do\n",
    "   trainData.data[i] = image.rgb2yuv(trainData.data[i])\n",
    "end\n",
    "--for i = 1,325 do\n",
    "  -- testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "--end\n",
    "-- Name channels for convenience\n",
    "channels = {'y','u','v'}\n",
    "\n",
    "-- Normalize each channel, and store mean/std\n",
    "-- per channel. These values are important, as they are part of\n",
    "-- the trainable parameters. At test time, test data will be normalized\n",
    "-- using these values.\n",
    "print '==> preprocessing data: normalize each feature (channel) globally'\n",
    "mean = {}\n",
    "std = {}\n",
    "for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   mean[i] = trainData.data[{ {},i,{},{} }]:mean()\n",
    "   std[i] = trainData.data[{ {},i,{},{} }]:std()\n",
    "   trainData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   trainData.data[{ {},i,{},{} }]:div(std[i])\n",
    "end\n",
    "\n",
    "-- Normalize test data, using the training means/stds\n",
    "--for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   --testData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   --testData.data[{ {},i,{},{} }]:div(std[i])\n",
    "--end\n",
    "-- Local normalization\n",
    "print '==> preprocessing data: normalize all three channels locally'\n",
    "\n",
    "-- Define the normalization neighborhood:\n",
    "neighborhood = image.gaussian1D(13)\n",
    "\n",
    "-- Define our local normalization operator (It is an actual nn module, \n",
    "-- which could be inserted into a trainable model):\n",
    "normalization = nn.SpatialContrastiveNormalization(1, neighborhood)\n",
    "\n",
    "-- Normalize all channels locally:\n",
    "for c in ipairs(channels) do\n",
    "   for i = 1,1685 do\n",
    "      trainData.data[{ i,{c},{},{} }] = normalization:forward(trainData.data[{ i,{c},{},{} }])\n",
    "   end\n",
    "   --for i = 1,325 do\n",
    "      --testData.data[{ i,{c},{},{} }] = normalization:forward(testData.data[{ i,{c},{},{} }])\n",
    "   --end\n",
    "end\n",
    "\n",
    "print '==> verify statistics'\n",
    "for i,channel in ipairs(channels) do\n",
    "   trainMean = trainData.data[{ {},i }]:mean()\n",
    "   trainStd = trainData.data[{ {},i }]:std()\n",
    "\n",
    "   --testMean = testData.data[{ {},i }]:mean()\n",
    "   --testStd = testData.data[{ {},i }]:std()\n",
    "\n",
    "   print('training data, '..channel..'-channel, mean: ' .. trainMean)\n",
    "   print('training data, '..channel..'-channel, standard deviation: ' .. trainStd)\n",
    "\n",
    "   --print('test data, '..channel..'-channel, mean: ' .. testMean)\n",
    "   --print('test data, '..channel..'-channel, standard deviation: ' .. testStd)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> vizualisation du modèle\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> output]\n",
       "  (1): nn.View(12288)\n",
       "  (2): nn.Linear(12288 -> 11)\n",
       "  (3): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nn.ClassNLLCriterion\n",
       "{\n",
       "  sizeAverage : true\n",
       "  output : 0\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  gradInput : DoubleTensor - empty\n",
       "  output_tensor : DoubleTensor - size: 1\n",
       "  target : LongTensor - size: 1\n",
       "  total_weight_tensor : DoubleTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- define model to train\n",
    "classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "\n",
    "model = nn.Sequential()\n",
    "\n",
    " --stage 1 : mean+std normalization -> filter bank -> squashing -> max pooling\n",
    "-- Convolution\n",
    "--model:add(nn.SpatialConvolutionMM(3,64,5,5))\n",
    "--model:add(nn.ReLU())\n",
    "--model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "-- stage 2 : filter bank -> squashing -> max pooling\n",
    "--model:add(nn.SpatialConvolutionMM(64,64,5,5))\n",
    "--model:add(nn.ReLU())\n",
    "--model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "\n",
    "-- stage 3 : standard 2-layer neural network\n",
    "-- Neural Network Linéaire\n",
    "model:add(nn.View(3*64*64))\n",
    "model:add(nn.Linear(3*64*64, #classes))\n",
    "--model:add(nn.ReLU())\n",
    "--model:add(nn.Linear(128,#classes))\n",
    "model:add(nn.LogSoftMax())\n",
    "print '==> vizualisation du modèle'\n",
    "print(model:__tostring())\n",
    "-- retrieve parameters and gradients. this helps us to use the optim package\n",
    "parameters,gradParameters = model:getParameters()\n",
    "-- loss function: negative log-likelihood\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "print (criterion)\n",
    "batchSize = 64 -- sets the mini-Batch size\n",
    "-- this matrix records the current confusion across classes\n",
    "confusion = optim.ConfusionMatrix(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- training function\n",
    "function train(dataset)\n",
    "   -- epoch tracker\n",
    "   epoch = epoch or 1\n",
    "\n",
    "   -- do one epoch\n",
    "   print('<trainer> on training set:')\n",
    "   print(\"<trainer> online epoch # \" .. epoch .. ' [batchSize = ' .. batchSize .. ']')\n",
    "   for t = 1,dataset:size(),batchSize do\n",
    "\n",
    "      -- create mini batch\n",
    "      local inputs = {}\n",
    "      local targets = {}\n",
    "      for i = t,math.min(t+batchSize-1,dataset:size()) do\n",
    "         -- load new sample\n",
    "         local input = dataset.data[i]\n",
    "         local target = dataset.labels[i]\n",
    "         table.insert(inputs, input)\n",
    "         table.insert(targets, target)\n",
    "      end\n",
    "      -- create closure to evaluate f(X) and df/dX\n",
    "      local feval = function(x)\n",
    "                       -- get new parameters\n",
    "                       if x ~= parameters then\n",
    "                          parameters:copy(x)\n",
    "                       end\n",
    "\n",
    "                       -- reset gradients\n",
    "                       gradParameters:zero()\n",
    "\n",
    "                       -- f is the average of all criterions\n",
    "                       local f = 0\n",
    "\n",
    "                       -- evaluate function for complete mini batch\n",
    "                       for i = 1,#inputs do\n",
    "                          -- estimate f\n",
    "                          local output = model:forward(inputs[i])\n",
    "                          local err = criterion:forward(output, targets[i])\n",
    "                          f = f + err\n",
    "\n",
    "                          -- estimate df/dW\n",
    "                          local df_do = criterion:backward(output, targets[i])\n",
    "                          model:backward(inputs[i], df_do)\n",
    "\n",
    "                          -- update confusion\n",
    "                          confusion:add(output, targets[i])                        \n",
    "                       end\n",
    "\n",
    "                       -- normalize gradients and f(X)\n",
    "                       gradParameters:div(#inputs)\n",
    "                       f = f/#inputs\n",
    "\n",
    "                       -- return f and df/dX\n",
    "                       return f,gradParameters\n",
    "                    end\n",
    "\n",
    "\n",
    "      config = config or {learningRate = 1e-3,\n",
    "              weightDecay = 0,\n",
    "                momentum = 0,\n",
    "              learningRateDecay = 5e-7}\n",
    "      optim.sgd(feval, parameters, config)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "   -- next epoch\n",
    "   epoch = epoch + 1\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 21 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     179       0       0       0       0       0       2       0       0       0       1]   98.352% \t[class: bridge]\n",
       " [       3     146       1       1       2       0       3       0       1       0       0]   92.994% \t[class: building]\n",
       " [       2       2      78       0       0       0       2       0       0       1       0]   91.765% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       3       2       0       0     212       0       2       3       1       0       0]   95.067% \t[class: elephant]\n",
       " [       0       0       1       0       0      43       0       0       0       0       0]   97.727% \t[class: landscape]\n",
       " [       0       1       1       0       3       0     279       1       0       2       1]   96.875% \t[class: lion]\n",
       " [       3       0       0       0       1       0       4     204       0       2       1]   94.884% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       1     162       0       0]   98.780% \t[class: people]\n",
       " [       1       0       0       0       2       0       2       0       0     148       0]   96.732% \t[class: tower]\n",
       " [       2       1       0       1       5       0       6       0       3       4     168]]  88.421% \t[class: water]\n",
       " + average row correct: 95.599709857594% \n",
       " + average rowUcol correct (VOC measure): 91.232256455855% \n",
       " + global correct: 95.22700814901%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.91232256455855\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.95599709857594\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.9522700814901\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 22 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     179       0       0       0       0       0       2       0       0       0       1]   98.352% \t[class: bridge]\n",
       " [       3     147       1       0       2       0       3       0       1       0       0]   93.631% \t[class: building]\n",
       " [       2       2      79       0       0       0       1       0       0       1       0]   92.941% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       3       2       0       0     214       0       2       1       1       0       0]   95.964% \t[class: elephant]\n",
       " [       0       0       1       0       0      43       0       0       0       0       0]   97.727% \t[class: landscape]\n",
       " [       0       1       1       0       1       0     281       1       0       2       1]   97.569% \t[class: lion]\n",
       " [       3       0       0       0       1       0       4     204       0       2       1]   94.884% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       2       0       2       0       0     149       0]   97.386% \t[class: tower]\n",
       " [       2       1       0       1       5       0       6       0       3       4     168]]  88.421% \t[class: water]\n",
       " + average row correct: 96.024080298164% \n",
       " + average rowUcol correct (VOC measure): 92.345065420324% \n",
       " + global correct: 95.69266589057%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.92345065420324\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.96024080298164\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.9569266589057\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 23 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     179       0       0       0       0       0       2       0       0       0       1]   98.352% \t[class: bridge]\n",
       " [       3     149       1       0       0       0       3       0       1       0       0]   94.904% \t[class: building]\n",
       " [       2       2      80       0       0       0       1       0       0       0       0]   94.118% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       3       2       0       0     214       0       2       1       1       0       0]   95.964% \t[class: elephant]\n",
       " [       0       0       1       0       0      43       0       0       0       0       0]   97.727% \t[class: landscape]\n",
       " [       0       1       1       0       1       0     281       1       0       2       1]   97.569% \t[class: lion]\n",
       " [       3       0       0       0       0       0       4     205       0       2       1]   95.349% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       2       0       2       0       0     149       0]   97.386% \t[class: tower]\n",
       " [       3       1       0       1       5       0       6       0       3       3     168]]  88.421% \t[class: water]\n",
       " + average row correct: 96.289122646505% \n",
       " + average rowUcol correct (VOC measure): 92.771723595533% \n",
       " + global correct: 95.92549476135%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.92771723595533\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.96289122646505\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.9592549476135\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 24 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     180       0       0       0       0       0       2       0       0       0       0]   98.901% \t[class: bridge]\n",
       " [       3     149       1       0       0       0       3       0       1       0       0]   94.904% \t[class: building]\n",
       " [       2       2      81       0       0       0       0       0       0       0       0]   95.294% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       3       1       0       0     216       0       1       1       1       0       0]   96.861% \t[class: elephant]\n",
       " [       0       0       1       0       0      43       0       0       0       0       0]   97.727% \t[class: landscape]\n",
       " [       0       1       1       0       1       0     283       0       0       2       0]   98.264% \t[class: lion]\n",
       " [       3       0       0       0       0       0       3     206       0       2       1]   95.814% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       2       0       2       0       0     149       0]   97.386% \t[class: tower]\n",
       " [       3       1       0       1       5       0       5       0       3       2     170]]  89.474% \t[class: water]\n",
       " + average row correct: 96.728666262193% \n",
       " + average rowUcol correct (VOC measure): 93.532599102367% \n",
       " + global correct: 96.449359720605%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.93532599102367\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.96728666262193\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.96449359720605\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 25 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     180       0       0       0       0       0       2       0       0       0       0]   98.901% \t[class: bridge]\n",
       " [       1     151       1       0       0       0       3       0       1       0       0]   96.178% \t[class: building]\n",
       " [       1       2      82       0       0       0       0       0       0       0       0]   96.471% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       3       1       0       0     216       0       1       1       1       0       0]   96.861% \t[class: elephant]\n",
       " [       0       0       1       0       0      43       0       0       0       0       0]   97.727% \t[class: landscape]\n",
       " [       0       1       1       0       1       0     283       0       0       2       0]   98.264% \t[class: lion]\n",
       " [       3       0       0       0       0       0       3     206       0       2       1]   95.814% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       2       0       1       0       0     150       0]   98.039% \t[class: tower]\n",
       " [       3       1       0       0       5       0       5       0       3       2     171]]  90.000% \t[class: water]\n",
       " + average row correct: 97.05869067799% \n",
       " + average rowUcol correct (VOC measure): 94.515481862155% \n",
       " + global correct: 96.74039580908%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.94515481862155\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.9705869067799\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.9674039580908\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 26 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     182       0       0       0       0       0       0       0       0       0       0]   100.000% \t[class: bridge]\n",
       " [       1     153       1       0       0       0       1       0       1       0       0]   97.452% \t[class: building]\n",
       " [       1       2      82       0       0       0       0       0       0       0       0]   96.471% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       3       1       0       0     217       0       1       1       0       0       0]   97.309% \t[class: elephant]\n",
       " [       0       0       0       0       0      44       0       0       0       0       0]   100.000% \t[class: landscape]\n",
       " [       0       1       1       0       1       0     283       0       0       2       0]   98.264% \t[class: lion]\n",
       " [       3       0       0       0       0       0       2     207       0       2       1]   96.279% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       1       0       1       0       0     151       0]   98.693% \t[class: tower]\n",
       " [       3       1       0       0       5       0       4       0       3       2     172]]  90.526% \t[class: water]\n",
       " + average row correct: 97.671324014664% \n",
       " + average rowUcol correct (VOC measure): 95.471831885251% \n",
       " + global correct: 97.264260768335%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.95471831885251\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.97671324014664\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.97264260768335\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 27 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     182       0       0       0       0       0       0       0       0       0       0]   100.000% \t[class: bridge]\n",
       " [       0     154       1       0       0       0       1       0       1       0       0]   98.089% \t[class: building]\n",
       " [       1       2      82       0       0       0       0       0       0       0       0]   96.471% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       2       1       0       0     218       0       1       1       0       0       0]   97.758% \t[class: elephant]\n",
       " [       0       0       0       0       0      44       0       0       0       0       0]   100.000% \t[class: landscape]\n",
       " [       0       1       1       0       1       0     283       0       0       2       0]   98.264% \t[class: lion]\n",
       " [       3       0       0       0       0       0       2     207       0       2       1]   96.279% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       1       0       1       0       0     151       0]   98.693% \t[class: tower]\n",
       " [       3       1       0       0       5       0       4       0       3       2     172]]  90.526% \t[class: water]\n",
       " + average row correct: 97.769994085485% \n",
       " + average rowUcol correct (VOC measure): 95.657241886312% \n",
       " + global correct: 97.380675203725%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.95657241886312\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.97769994085485\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       " "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.97380675203725\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 28 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     182       0       0       0       0       0       0       0       0       0       0]   100.000% \t[class: bridge]\n",
       " [       0     154       1       0       0       0       1       1       0       0       0]   98.089% \t[class: building]\n",
       " [       1       1      83       0       0       0       0       0       0       0       0]   97.647% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       1       0       0       0     220       0       1       1       0       0       0]   98.655% \t[class: elephant]\n",
       " [       0       0       0       0       0      44       0       0       0       0       0]   100.000% \t[class: landscape]\n",
       " [       0       1       1       0       1       0     283       0       0       2       0]   98.264% \t[class: lion]\n",
       " [       2       0       0       0       0       0       1     209       0       2       1]   97.209% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       1       0       1       0       0     151       0]   98.693% \t[class: tower]\n",
       " [       3       1       0       0       5       0       4       0       3       2     172]]  90.526% \t[class: water]\n",
       " + average row correct: 98.043046214364% \n",
       " + average rowUcol correct (VOC measure): 96.166002750397% \n",
       " + global correct: 97.6717112922%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.96166002750397\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.98043046214364\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.976717112922\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 29 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     182       0       0       0       0       0       0       0       0       0       0]   100.000% \t[class: bridge]\n",
       " [       0     155       1       0       0       0       0       1       0       0       0]   98.726% \t[class: building]\n",
       " [       1       1      83       0       0       0       0       0       0       0       0]   97.647% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       1       0       0       0     220       0       1       1       0       0       0]   98.655% \t[class: elephant]\n",
       " [       0       0       0       0       0      44       0       0       0       0       0]   100.000% \t[class: landscape]\n",
       " [       0       1       1       0       1       0     283       0       0       2       0]   98.264% \t[class: lion]\n",
       " [       1       0       0       0       0       0       1     210       0       2       1]   97.674% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       1       0       1       0       0     151       0]   98.693% \t[class: tower]\n",
       " [       2       1       0       0       5       0       3       0       3       2     174]]  91.579% \t[class: water]\n",
       " + average row correct: 98.238927125931% \n",
       " + average rowUcol correct (VOC measure): 96.51226292957% \n",
       " + global correct: 97.90454016298%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.9651226292957\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.98238927125931\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.9790454016298\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 30 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     182       0       0       0       0       0       0       0       0       0       0]   100.000% \t[class: bridge]\n",
       " [       0     155       1       0       0       0       0       1       0       0       0]   98.726% \t[class: building]\n",
       " [       1       1      83       0       0       0       0       0       0       0       0]   97.647% \t[class: city]\n",
       " [       0       0       0      17       0       0       0       0       0       0       0]   100.000% \t[class: eiffel_tower]\n",
       " [       1       0       0       0     220       0       1       1       0       0       0]   98.655% \t[class: elephant]\n",
       " [       0       0       0       0       0      44       0       0       0       0       0]   100.000% \t[class: landscape]\n",
       " [       0       0       1       0       1       0     284       0       0       2       0]   98.611% \t[class: lion]\n",
       " [       1       0       0       0       0       0       1     210       0       2       1]   97.674% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       1       0     163       0       0]   99.390% \t[class: people]\n",
       " [       0       0       0       0       1       0       1       0       0     151       0]   98.693% \t[class: tower]\n",
       " [       2       1       0       0       4       0       3       0       2       2     176]]  92.632% \t[class: water]\n",
       " + average row correct: 98.366186293689% \n",
       " + average rowUcol correct (VOC measure): 96.785085851496% \n",
       " + global correct: 98.079161816065%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.96785085851496\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.98366186293689\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.98079161816065\n",
       "}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "while i<10 do\n",
    "train(trainData)\n",
    "i=i+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "0\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "32\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "64\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "96\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "128\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "160\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "192\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "224\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "256\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "1567\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "total\t1599\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "totaltest = 0\n",
    "for dir in paths.iterdirs(\"./dataset/val/\") do\n",
    "    files = {}\n",
    "    print(files)\n",
    "    for file in paths.files(paths.concat('./dataset/val/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, 1)\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "    print(totaltest)\n",
    "    totaltest = totaltest + #files\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print('total', totaltest)\n",
    "--[[\n",
    "imagesAll = torch.Tensor(totaltest,3,64,64) \n",
    "labelsAll = torch.Tensor(totaltest)\n",
    "compteur = 0\n",
    "NumberOfImages = {0}\n",
    "for dir in paths.iterdirs(\"./dataset/val/\") do\n",
    "    compteur = compteur +1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/val/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/val/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    lastElement = NumberOfImages[#NumberOfImages]\n",
    "    table.insert(NumberOfImages, #files + lastElement)\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "        temp2 = torch.Tensor(3,64,64) \n",
    "        if (temp:size()[1]==1) then\n",
    "            temp2[{{1},{},{}}] = temp\n",
    "            temp2[{{2},{},{}}] = temp\n",
    "            temp2[{{3},{},{}}] = temp\n",
    "        else \n",
    "            temp2 = temp\n",
    "        end\n",
    "        imagesAll[i+lastElement] = temp2 \n",
    "        labelsAll[i+lastElement] = compteur\n",
    "    end\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "\n",
    "-- Nombre d'images courleurs: 1683 \n",
    "testData = {\n",
    "    data = torch.Tensor(totaltest, 3, 64, 64),\n",
    "    labels = torch.Tensor(totaltest),\n",
    "    size = function() return totaltest end,\n",
    "\n",
    "}\n",
    "--[[create test set:\n",
    "testData = {\n",
    "      data = torch.Tensor(tesize, 1, 32, 32),\n",
    "      labels = torch.Tensor(tesize),\n",
    "      size = function() return tesize end\n",
    "   }\n",
    "]]--\n",
    "\n",
    "for i=1,totaltest do\n",
    "   testData.data[i] = imagesAll[i]\n",
    "   testData.labels[i] = labelsAll[i]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
