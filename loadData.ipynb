{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "Dan Constantini, Tom Hayat et Alexandre Attia\n",
    "This script loads 11 data class from imagenet and sort the files according to their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total\t1718\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'\n",
    "require 'xlua'\n",
    "require 'image'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "\n",
    "\n",
    "--classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "total = 0\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, 1)\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    total = total + #files\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print('total', total)\n",
    "\n",
    "imagesAll = torch.Tensor(total,3,64,64) \n",
    "labelsAll = torch.Tensor(total)\n",
    "compteur = 0\n",
    "NumberOfImages = {0}\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    compteur = compteur +1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/train/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    lastElement = NumberOfImages[#NumberOfImages]\n",
    "    table.insert(NumberOfImages, #files + lastElement)\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "        temp2 = torch.Tensor(3,64,64) \n",
    "        if (temp:size()[1]==1) then\n",
    "            temp2[{{1},{},{}}] = temp\n",
    "            temp2[{{2},{},{}}] = temp\n",
    "            temp2[{{3},{},{}}] = temp\n",
    "        else \n",
    "            temp2 = temp\n",
    "        end\n",
    "        imagesAll[i+lastElement] = temp2 \n",
    "        labelsAll[i+lastElement] = compteur\n",
    "    end\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "\n",
    "-- Nombre d'images courleurs: 1683 \n",
    "trainData = {\n",
    "    data = torch.Tensor(total, 3, 64, 64),\n",
    "    labels = torch.Tensor(total),\n",
    "    size = function() return total end,\n",
    "\n",
    "}\n",
    "--[[create test set:\n",
    "testData = {\n",
    "      data = torch.Tensor(tesize, 1, 32, 32),\n",
    "      labels = torch.Tensor(tesize),\n",
    "      size = function() return tesize end\n",
    "   }\n",
    "]]--\n",
    "\n",
    "for i=1,total do\n",
    "   trainData.data[i] = imagesAll[i]\n",
    "   trainData.labels[i] = labelsAll[i]\n",
    "end\n",
    "--for i=trsize+1,tesize+trsize do\n",
    "   --testData.data[i-trsize] = imagesAll[labelsShuffle[i]][1]:clone()\n",
    "   --testData.labels[i-trsize] = labelsAll[labelsShuffle[i]]\n",
    "--end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : DoubleTensor - size: 1718x3x64x64\n",
       "  size : function: 0x0ae38b00\n",
       "  labels : DoubleTensor - size: 1718\n",
       "}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--for i=1,total do \n",
    "    --itorch.image(imagesAll[i])\n",
    "    --print(labelsAll[i])\n",
    "--end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problème :</b> à partir de l'image 288, les images sont entierement noirs et le label est nul. Je pense qu'il y a un probleme avec le `if (temp:size()[1]==3) then` ! En fait c'est avant je crois, quand on print le nombre de files ils en mettent que 190 .. --> J'ai compris on a un probleme dans la boucle, en fait, elle repart de 0 à chaque fois pour imageAll, donc à chaque fois qu'on parcourt un repertory d'images on réécrit sur les images anciennes (la liste `files` est temporaire. Le nombres d'images dans imagesAll est donc 288 car le nombre maximal d'images des dossiers du dataset est 288. \n",
    "\n",
    "``for i=1,(#files) do\n",
    "        print('dossier : ', compteur)\n",
    "        print(#files)\n",
    "        temp = image.load(files[i])\n",
    "        --print(files[i])\n",
    "        if (temp:size()[1]==3) then\n",
    "            imagesAll[i] = image.load(files[i]) \n",
    "            labelsAll[i] = compteur\n",
    "        end\n",
    "    end\n",
    "``\n",
    "\n",
    "Est ce que ce code là on le sort pas de la grosse boucle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: colorspace RGB -> YUV\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize each feature (channel) globally\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize all three channels locally\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> verify statistics\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, y-channel, mean: -0.014755872570939\t\n",
       "training data, y-channel, standard deviation: 0.87619051860649\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, u-channel, mean: 0.01716397024165\t\n",
       "training data, u-channel, standard deviation: 0.86160707019696\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, v-channel, mean: -0.015114343104192\t\n",
       "training data, v-channel, standard deviation: 0.85675725071268\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Convert all images to YUV\n",
    "print '==> preprocessing data: colorspace RGB -> YUV'\n",
    "for i = 1,total do\n",
    "   trainData.data[i] = image.rgb2yuv(trainData.data[i])\n",
    "end\n",
    "--for i = 1,325 do\n",
    "  -- testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "--end\n",
    "-- Name channels for convenience\n",
    "channels = {'y','u','v'}\n",
    "\n",
    "-- Normalize each channel, and store mean/std\n",
    "-- per channel. These values are important, as they are part of\n",
    "-- the trainable parameters. At test time, test data will be normalized\n",
    "-- using these values.\n",
    "print '==> preprocessing data: normalize each feature (channel) globally'\n",
    "mean = {}\n",
    "std = {}\n",
    "for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   mean[i] = trainData.data[{ {},i,{},{} }]:mean()\n",
    "   std[i] = trainData.data[{ {},i,{},{} }]:std()\n",
    "   trainData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   trainData.data[{ {},i,{},{} }]:div(std[i])\n",
    "end\n",
    "\n",
    "-- Normalize test data, using the training means/stds\n",
    "--for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   --testData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   --testData.data[{ {},i,{},{} }]:div(std[i])\n",
    "--end\n",
    "-- Local normalization\n",
    "print '==> preprocessing data: normalize all three channels locally'\n",
    "\n",
    "-- Define the normalization neighborhood:\n",
    "neighborhood = image.gaussian1D(13)\n",
    "\n",
    "-- Define our local normalization operator (It is an actual nn module, \n",
    "-- which could be inserted into a trainable model):\n",
    "normalization = nn.SpatialContrastiveNormalization(1, neighborhood)\n",
    "\n",
    "-- Normalize all channels locally:\n",
    "for c in ipairs(channels) do\n",
    "   for i = 1,total do\n",
    "      trainData.data[{ i,{c},{},{} }] = normalization:forward(trainData.data[{ i,{c},{},{} }])\n",
    "   end\n",
    "   --for i = 1,325 do\n",
    "      --testData.data[{ i,{c},{},{} }] = normalization:forward(testData.data[{ i,{c},{},{} }])\n",
    "   --end\n",
    "end\n",
    "\n",
    "print '==> verify statistics'\n",
    "for i,channel in ipairs(channels) do\n",
    "   trainMean = trainData.data[{ {},i }]:mean()\n",
    "   trainStd = trainData.data[{ {},i }]:std()\n",
    "\n",
    "   --testMean = testData.data[{ {},i }]:mean()\n",
    "   --testStd = testData.data[{ {},i }]:std()\n",
    "\n",
    "   print('training data, '..channel..'-channel, mean: ' .. trainMean)\n",
    "   print('training data, '..channel..'-channel, standard deviation: ' .. trainStd)\n",
    "\n",
    "   --print('test data, '..channel..'-channel, mean: ' .. testMean)\n",
    "   --print('test data, '..channel..'-channel, standard deviation: ' .. testStd)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> define parameters\t\n",
       "==> construct model\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> vizualisation du modèle\t\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> output]\n",
       "  (1): nn.Reshape(12288)\n",
       "  (2): nn.Linear(12288 -> 6144)\n",
       "  (3): nn.Tanh\n",
       "  (4): nn.Linear(6144 -> 11)\n",
       "}\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nn.ClassNLLCriterion\n",
       "{\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  sizeAverage : true\n",
       "  output : 0\n",
       "  gradInput : DoubleTensor - empty\n",
       "  output_tensor : DoubleTensor - size: 1\n",
       "  target : LongTensor - size: 1\n",
       "  total_weight_tensor : DoubleTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- define model to train\n",
    "classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "\n",
    "print '==> define parameters'\n",
    "\n",
    "-- 10-class problem\n",
    "noutputs = 11\n",
    "\n",
    "-- input dimensions\n",
    "nfeats = 3\n",
    "width = 64\n",
    "height = 64\n",
    "ninputs = nfeats*width*height\n",
    "\n",
    "-- number of hidden units (for MLP only):\n",
    "nhiddens = ninputs / 2\n",
    "\n",
    "-- hidden units, filter sizes (for ConvNet only):\n",
    "nstates = {64,64,128}\n",
    "filtsize = 5\n",
    "poolsize = 2\n",
    "normkernel = image.gaussian1D(13)\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print '==> construct model'\n",
    "\n",
    "model='mlp'\n",
    "\n",
    "if model == 'linear' then\n",
    "\n",
    "   -- Simple linear model\n",
    "   model = nn.Sequential()\n",
    "   model:add(nn.Reshape(ninputs))\n",
    "   model:add(nn.Linear(ninputs,noutputs))\n",
    "\n",
    "elseif model == 'mlp' then\n",
    "\n",
    "   -- Simple 2-layer neural network, with tanh hidden units\n",
    "   model = nn.Sequential()\n",
    "   model:add(nn.Reshape(ninputs))\n",
    "   model:add(nn.Linear(ninputs,nhiddens))\n",
    "   model:add(nn.Tanh())\n",
    "   model:add(nn.Linear(nhiddens,noutputs))\n",
    "\n",
    "elseif model == 'convnet' then\n",
    "\n",
    "      -- a typical convolutional network, with locally-normalized hidden\n",
    "      -- units, and L2-pooling\n",
    "\n",
    "      model = nn.Sequential()\n",
    "\n",
    "      -- stage 1 : filter bank -> squashing -> L2 pooling -> normalization\n",
    "      model:add(nn.SpatialConvolutionMM(nfeats, nstates[1], filtsize, filtsize))\n",
    "      model:add(nn.Tanh())\n",
    "      model:add(nn.SpatialLPPooling(nstates[1],2,poolsize,poolsize,poolsize,poolsize))\n",
    "      model:add(nn.SpatialSubtractiveNormalization(nstates[1], normkernel))\n",
    "\n",
    "      -- stage 2 : filter bank -> squashing -> L2 pooling -> normalization\n",
    "      model:add(nn.SpatialConvolutionMM(nstates[1], nstates[2], filtsize, filtsize))\n",
    "      model:add(nn.Tanh())\n",
    "      model:add(nn.SpatialLPPooling(nstates[2],2,poolsize,poolsize,poolsize,poolsize))\n",
    "      model:add(nn.SpatialSubtractiveNormalization(nstates[2], normkernel))\n",
    "\n",
    "      -- stage 3 : standard 2-layer neural network\n",
    "      model:add(nn.Reshape(nstates[2]*filtsize*filtsize))\n",
    "      model:add(nn.Linear(nstates[2]*filtsize*filtsize, nstates[3]))\n",
    "      model:add(nn.Tanh())\n",
    "      model:add(nn.Linear(nstates[3], noutputs))\n",
    "end\n",
    "\n",
    "print '==> vizualisation du modèle'\n",
    "print(model:__tostring())\n",
    "-- retrieve parameters and gradients. this helps us to use the optim package\n",
    "parameters,gradParameters = model:getParameters()\n",
    "-- loss function: negative log-likelihood\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "print (criterion)\n",
    "batchSize = 64 -- sets the mini-Batch size\n",
    "-- this matrix records the current confusion across classes\n",
    "confusion = optim.ConfusionMatrix(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- training function\n",
    "function train(dataset)\n",
    "   -- epoch tracker\n",
    "   epoch = epoch or 1\n",
    "\n",
    "   -- do one epoch\n",
    "   print('<trainer> on training set:')\n",
    "   print(\"<trainer> online epoch # \" .. epoch .. ' [batchSize = ' .. batchSize .. ']')\n",
    "   for t = 1,dataset:size(),batchSize do\n",
    "\n",
    "      -- create mini batch\n",
    "      local inputs = {}\n",
    "      local targets = {}\n",
    "      for i = t,math.min(t+batchSize-1,dataset:size()) do\n",
    "         -- load new sample\n",
    "         local input = dataset.data[i]\n",
    "         local target = dataset.labels[i]\n",
    "         table.insert(inputs, input)\n",
    "         table.insert(targets, target)\n",
    "      end\n",
    "      -- create closure to evaluate f(X) and df/dX\n",
    "      local feval = function(x)\n",
    "                       -- get new parameters\n",
    "                       if x ~= parameters then\n",
    "                          parameters:copy(x)\n",
    "                       end\n",
    "\n",
    "                       -- reset gradients\n",
    "                       gradParameters:zero()\n",
    "\n",
    "                       -- f is the average of all criterions\n",
    "                       local f = 0\n",
    "\n",
    "                       -- evaluate function for complete mini batch\n",
    "                       for i = 1,#inputs do\n",
    "                          -- estimate f\n",
    "                          local output = model:forward(inputs[i])\n",
    "                          local err = criterion:forward(output, targets[i])\n",
    "                          f = f + err\n",
    "\n",
    "                          -- estimate df/dW\n",
    "                          local df_do = criterion:backward(output, targets[i])\n",
    "                          model:backward(inputs[i], df_do)\n",
    "\n",
    "                          -- update confusion\n",
    "                          confusion:add(output, targets[i])                        \n",
    "                       end\n",
    "\n",
    "                       -- normalize gradients and f(X)\n",
    "                       gradParameters:div(#inputs)\n",
    "                       f = f/#inputs\n",
    "\n",
    "                       -- return f and df/dX\n",
    "                       return f,gradParameters\n",
    "                    end\n",
    "\n",
    "\n",
    "      config = config or {learningRate = 1e-3,\n",
    "              weightDecay = 0,\n",
    "                momentum = 0,\n",
    "              learningRateDecay = 5e-7}\n",
    "      optim.sgd(feval, parameters, config)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "   -- next epoch\n",
    "   epoch = epoch + 1\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "64\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "96\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "128\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "160\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "192\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "224\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "256\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "288\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "total\t320\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: colorspace RGB -> YUV\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize each feature (channel) globally\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize all three channels locally\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> verify statistics\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, y-channel, mean: -0.014682043068754\t\n",
       "test data, y-channel, standard deviation: 0.8770891870443\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, u-channel, mean: 0.018090772041077\t\n",
       "test data, u-channel, standard deviation: 0.86623959227628\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, v-channel, mean: -0.016709132318742\t\n",
       "test data, v-channel, standard deviation: 0.86127668997906\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "totaltest = 0\n",
    "for dir in paths.iterdirs(\"./dataset/val/\") do\n",
    "    files = {}\n",
    "    print(files)\n",
    "    for file in paths.files(paths.concat('./dataset/val/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, 1)\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "    print(totaltest)\n",
    "    totaltest = totaltest + #files\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print('total', totaltest)\n",
    "\n",
    "imagesAll = torch.Tensor(totaltest,3,64,64) \n",
    "labelsAll = torch.Tensor(totaltest)\n",
    "compteur = 0\n",
    "NumberOfImages = {0}\n",
    "for dir in paths.iterdirs(\"./dataset/val/\") do\n",
    "    compteur = compteur +1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/val/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/val/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    lastElement = NumberOfImages[#NumberOfImages]\n",
    "    table.insert(NumberOfImages, #files + lastElement)\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "        temp2 = torch.Tensor(3,64,64) \n",
    "        if (temp:size()[1]==1) then\n",
    "            temp2[{{1},{},{}}] = temp\n",
    "            temp2[{{2},{},{}}] = temp\n",
    "            temp2[{{3},{},{}}] = temp\n",
    "        else \n",
    "            temp2 = temp\n",
    "        end\n",
    "        imagesAll[i+lastElement] = temp2 \n",
    "        labelsAll[i+lastElement] = compteur\n",
    "    end\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "\n",
    "-- Nombre d'images courleurs: 1683 \n",
    "testData = {\n",
    "    data = torch.Tensor(totaltest, 3, 64, 64),\n",
    "    labels = torch.Tensor(totaltest),\n",
    "    size = function() return totaltest end,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "for i=1,totaltest do\n",
    "   testData.data[i] = imagesAll[i]\n",
    "   testData.labels[i] = labelsAll[i]\n",
    "end\n",
    "\n",
    "-- Convert all images to YUV\n",
    "print '==> preprocessing data: colorspace RGB -> YUV'\n",
    "for i = 1,totaltest do\n",
    "   testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "end\n",
    "--for i = 1,325 do\n",
    "  -- testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "--end\n",
    "-- Name channels for convenience\n",
    "channels = {'y','u','v'}\n",
    "\n",
    "-- Normalize each channel, and store mean/std\n",
    "-- per channel. These values are important, as they are part of\n",
    "-- the trainable parameters. At test time, test data will be normalized\n",
    "-- using these values.\n",
    "print '==> preprocessing data: normalize each feature (channel) globally'\n",
    "--mean = {}\n",
    "--std = {}\n",
    "for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   testData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   testData.data[{ {},i,{},{} }]:div(std[i])\n",
    "end\n",
    "\n",
    "-- Local normalization\n",
    "print '==> preprocessing data: normalize all three channels locally'\n",
    "\n",
    "-- Define the normalization neighborhood:\n",
    "neighborhood = image.gaussian1D(13)\n",
    "\n",
    "-- Define our local normalization operator (It is an actual nn module, \n",
    "-- which could be inserted into a trainable model):\n",
    "normalization = nn.SpatialContrastiveNormalization(1, neighborhood)\n",
    "\n",
    "-- Normalize all channels locally:\n",
    "for c in ipairs(channels) do\n",
    "\n",
    "   for i = 1,totaltest do\n",
    "      testData.data[{ i,{c},{},{} }] = normalization:forward(testData.data[{ i,{c},{},{} }])\n",
    "   end\n",
    "end\n",
    "\n",
    "print '==> verify statistics'\n",
    "for i,channel in ipairs(channels) do\n",
    "\n",
    "   testMean = testData.data[{ {},i }]:mean()\n",
    "   testStd = testData.data[{ {},i }]:std()\n",
    "\n",
    "\n",
    "   print('test data, '..channel..'-channel, mean: ' .. testMean)\n",
    "   print('test data, '..channel..'-channel, standard deviation: ' .. testStd)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- test function\n",
    "function test(dataset)\n",
    "\n",
    "   -- test over given dataset\n",
    "   print('<trainer> on testing Set:')\n",
    "   for t = 1,dataset:size() do\n",
    "      -- get new sample\n",
    "      local input = dataset.data[t]\n",
    "      local target = dataset.labels[t]\n",
    "\n",
    "      -- test sample\n",
    "      local pred = model:forward(input)\n",
    "      confusion:add(pred, target)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 1 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "while i<10 do\n",
    "train(trainData)\n",
    "test(testData)\n",
    "i=i+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
