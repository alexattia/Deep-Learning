{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "Dan Constantini, Tom Hayat et Alexandre Attia\n",
    "This script loads 11 data class from imagenet and sort the files according to their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total\t1718\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'\n",
    "require 'xlua'\n",
    "require 'image'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "\n",
    "\n",
    "--classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "total = 0\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, 1)\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    total = total + #files\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print('total', total)\n",
    "\n",
    "imagesAll = torch.Tensor(total,3,64,64) \n",
    "labelsAll = torch.Tensor(total)\n",
    "compteur = 0\n",
    "NumberOfImages = {0}\n",
    "for dir in paths.iterdirs(\"./dataset/train/\") do\n",
    "    compteur = compteur +1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/train/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/train/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    lastElement = NumberOfImages[#NumberOfImages]\n",
    "    table.insert(NumberOfImages, #files + lastElement)\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "        temp2 = torch.Tensor(3,64,64) \n",
    "        if (temp:size()[1]==1) then\n",
    "            temp2[{{1},{},{}}] = temp\n",
    "            temp2[{{2},{},{}}] = temp\n",
    "            temp2[{{3},{},{}}] = temp\n",
    "        else \n",
    "            temp2 = temp\n",
    "        end\n",
    "        imagesAll[i+lastElement] = temp2 \n",
    "        labelsAll[i+lastElement] = compteur\n",
    "    end\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "\n",
    "-- Nombre d'images courleurs: 1683 \n",
    "trainData = {\n",
    "    data = torch.Tensor(total, 3, 64, 64),\n",
    "    labels = torch.Tensor(total),\n",
    "    size = function() return total end,\n",
    "\n",
    "}\n",
    "--[[create test set:\n",
    "testData = {\n",
    "      data = torch.Tensor(tesize, 1, 32, 32),\n",
    "      labels = torch.Tensor(tesize),\n",
    "      size = function() return tesize end\n",
    "   }\n",
    "]]--\n",
    "\n",
    "for i=1,total do\n",
    "   trainData.data[i] = imagesAll[i]\n",
    "   trainData.labels[i] = labelsAll[i]\n",
    "end\n",
    "--for i=trsize+1,tesize+trsize do\n",
    "   --testData.data[i-trsize] = imagesAll[labelsShuffle[i]][1]:clone()\n",
    "   --testData.labels[i-trsize] = labelsAll[labelsShuffle[i]]\n",
    "--end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : DoubleTensor - size: 1718x3x64x64\n",
       "  size : function: 0x0eb1ee58\n",
       "  labels : DoubleTensor - size: 1718\n",
       "}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--for i=1,total do \n",
    "    --itorch.image(imagesAll[i])\n",
    "    --print(labelsAll[i])\n",
    "--end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problème :</b> à partir de l'image 288, les images sont entierement noirs et le label est nul. Je pense qu'il y a un probleme avec le `if (temp:size()[1]==3) then` ! En fait c'est avant je crois, quand on print le nombre de files ils en mettent que 190 .. --> J'ai compris on a un probleme dans la boucle, en fait, elle repart de 0 à chaque fois pour imageAll, donc à chaque fois qu'on parcourt un repertory d'images on réécrit sur les images anciennes (la liste `files` est temporaire. Le nombres d'images dans imagesAll est donc 288 car le nombre maximal d'images des dossiers du dataset est 288. \n",
    "\n",
    "``for i=1,(#files) do\n",
    "        print('dossier : ', compteur)\n",
    "        print(#files)\n",
    "        temp = image.load(files[i])\n",
    "        --print(files[i])\n",
    "        if (temp:size()[1]==3) then\n",
    "            imagesAll[i] = image.load(files[i]) \n",
    "            labelsAll[i] = compteur\n",
    "        end\n",
    "    end\n",
    "``\n",
    "\n",
    "Est ce que ce code là on le sort pas de la grosse boucle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: colorspace RGB -> YUV\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize each feature (channel) globally\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize all three channels locally\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> verify statistics\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, y-channel, mean: -0.014755872570939\t\n",
       "training data, y-channel, standard deviation: 0.87619051860649\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, u-channel, mean: 0.01716397024165\t\n",
       "training data, u-channel, standard deviation: 0.86160707019696\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training data, v-channel, mean: -0.015114343104192\t\n",
       "training data, v-channel, standard deviation: 0.85675725071268\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Convert all images to YUV\n",
    "collectgarbage()\n",
    "print '==> preprocessing data: colorspace RGB -> YUV'\n",
    "for i = 1,total do\n",
    "   trainData.data[i] = image.rgb2yuv(trainData.data[i])\n",
    "end\n",
    "--for i = 1,325 do\n",
    "  -- testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "--end\n",
    "-- Name channels for convenience\n",
    "channels = {'y','u','v'}\n",
    "\n",
    "-- Normalize each channel, and store mean/std\n",
    "-- per channel. These values are important, as they are part of\n",
    "-- the trainable parameters. At test time, test data will be normalized\n",
    "-- using these values.\n",
    "print '==> preprocessing data: normalize each feature (channel) globally'\n",
    "mean = {}\n",
    "std = {}\n",
    "for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   mean[i] = trainData.data[{ {},i,{},{} }]:mean()\n",
    "   std[i] = trainData.data[{ {},i,{},{} }]:std()\n",
    "   trainData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   trainData.data[{ {},i,{},{} }]:div(std[i])\n",
    "end\n",
    "\n",
    "-- Normalize test data, using the training means/stds\n",
    "--for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   --testData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   --testData.data[{ {},i,{},{} }]:div(std[i])\n",
    "--end\n",
    "-- Local normalization\n",
    "print '==> preprocessing data: normalize all three channels locally'\n",
    "\n",
    "-- Define the normalization neighborhood:\n",
    "neighborhood = image.gaussian1D(13)\n",
    "\n",
    "-- Define our local normalization operator (It is an actual nn module, \n",
    "-- which could be inserted into a trainable model):\n",
    "normalization = nn.SpatialContrastiveNormalization(1, neighborhood)\n",
    "\n",
    "-- Normalize all channels locally:\n",
    "for c in ipairs(channels) do\n",
    "   for i = 1,total do\n",
    "      trainData.data[{ i,{c},{},{} }] = normalization:forward(trainData.data[{ i,{c},{},{} }])\n",
    "   end\n",
    "   --for i = 1,325 do\n",
    "      --testData.data[{ i,{c},{},{} }] = normalization:forward(testData.data[{ i,{c},{},{} }])\n",
    "   --end\n",
    "end\n",
    "\n",
    "print '==> verify statistics'\n",
    "for i,channel in ipairs(channels) do\n",
    "   trainMean = trainData.data[{ {},i }]:mean()\n",
    "   trainStd = trainData.data[{ {},i }]:std()\n",
    "\n",
    "   --testMean = testData.data[{ {},i }]:mean()\n",
    "   --testStd = testData.data[{ {},i }]:std()\n",
    "\n",
    "   print('training data, '..channel..'-channel, mean: ' .. trainMean)\n",
    "   print('training data, '..channel..'-channel, standard deviation: ' .. trainStd)\n",
    "\n",
    "   --print('test data, '..channel..'-channel, mean: ' .. testMean)\n",
    "   --print('test data, '..channel..'-channel, standard deviation: ' .. testStd)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> vizualisation du modèle\t\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]\n",
       "  (1): nn.SpatialConvolutionMM(3 -> 64, 5x5)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (4): nn.SpatialConvolutionMM(64 -> 64, 5x5)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (7): nn.View(10816)\n",
       "  (8): nn.Linear(10816 -> 11)\n",
       "  (9): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nn.ClassNLLCriterion\n",
       "{\n",
       "  sizeAverage : true\n",
       "  output : 0\n",
       "  gradInput : DoubleTensor - empty\n",
       "  output_tensor : DoubleTensor - size: 1\n",
       "  target : LongTensor - size: 1\n",
       "  total_weight_tensor : DoubleTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- define model to train\n",
    "classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "-- define model to train\n",
    "\n",
    "model = nn.Sequential()\n",
    " --stage 1 : mean+std normalization -> filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(3,64,5,5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "-- stage 2 : filter bank -> squashing -> max pooling\n",
    "model:add(nn.SpatialConvolutionMM(64,64,5,5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2, 2, 2))\n",
    "\n",
    "-- stage 3 : standard 2-layer neural network\n",
    "model:add(nn.View(64*13*13))\n",
    "model:add(nn.Linear(64*13*13, #classes))\n",
    "--model:add(nn.ReLU())\n",
    "--model:add(nn.Linear(128,#classes))\n",
    "model:add(nn.LogSoftMax())\n",
    "\n",
    "print '==> vizualisation du modèle'\n",
    "print(model:__tostring())\n",
    "-- retrieve parameters and gradients. this helps us to use the optim package\n",
    "parameters,gradParameters = model:getParameters()\n",
    "-- loss function: negative log-likelihood\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "print (criterion)\n",
    "batchSize = 64 -- sets the mini-Batch size\n",
    "-- this matrix records the current confusion across classes\n",
    "confusion = optim.ConfusionMatrix(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- training function\n",
    "collectgarbage()\n",
    "function train(dataset)\n",
    "   -- epoch tracker\n",
    "   epoch = epoch or 1\n",
    "\n",
    "   -- do one epoch\n",
    "   print('<trainer> on training set:')\n",
    "   print(\"<trainer> online epoch # \" .. epoch .. ' [batchSize = ' .. batchSize .. ']')\n",
    "   for t = 1,dataset:size(),batchSize do\n",
    "\n",
    "      -- create mini batch\n",
    "      local inputs = {}\n",
    "      local targets = {}\n",
    "      for i = t,math.min(t+batchSize-1,dataset:size()) do\n",
    "         -- load new sample\n",
    "         local input = dataset.data[i]\n",
    "         local target = dataset.labels[i]\n",
    "         table.insert(inputs, input)\n",
    "         table.insert(targets, target)\n",
    "      end\n",
    "      -- create closure to evaluate f(X) and df/dX\n",
    "      local feval = function(x)\n",
    "                       -- get new parameters\n",
    "                       if x ~= parameters then\n",
    "                          parameters:copy(x)\n",
    "                       end\n",
    "\n",
    "                       -- reset gradients\n",
    "                       gradParameters:zero()\n",
    "\n",
    "                       -- f is the average of all criterions\n",
    "                       local f = 0\n",
    "\n",
    "                       -- evaluate function for complete mini batch\n",
    "                       for i = 1,#inputs do\n",
    "                          -- estimate f\n",
    "                          local output = model:forward(inputs[i])\n",
    "                          local err = criterion:forward(output, targets[i])\n",
    "                          f = f + err\n",
    "\n",
    "                          -- estimate df/dW\n",
    "                          local df_do = criterion:backward(output, targets[i])\n",
    "                          model:backward(inputs[i], df_do)\n",
    "\n",
    "                          -- update confusion\n",
    "                          confusion:add(output, targets[i])                        \n",
    "                       end\n",
    "\n",
    "                       -- normalize gradients and f(X)\n",
    "                       gradParameters:div(#inputs)\n",
    "                       f = f/#inputs\n",
    "\n",
    "                       -- return f and df/dX\n",
    "                       return f,gradParameters\n",
    "                    end\n",
    "\n",
    "\n",
    "      config = config or {learningRate = 1e-3,\n",
    "              weightDecay = 0,\n",
    "                momentum = 0,\n",
    "              learningRateDecay = 5e-7}\n",
    "      optim.sgd(feval, parameters, config)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "   -- next epoch\n",
    "   epoch = epoch + 1\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "64\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "96\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "128\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "160\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n",
       "192\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "224\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "256\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "}\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "288\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "total\t320\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: colorspace RGB -> YUV\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize each feature (channel) globally\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> preprocessing data: normalize all three channels locally\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> verify statistics\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, y-channel, mean: -0.014682043068754\t\n",
       "test data, y-channel, standard deviation: 0.8770891870443\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, u-channel, mean: 0.018090772041077\t\n",
       "test data, u-channel, standard deviation: 0.86623959227628\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "test data, v-channel, mean: -0.016709132318742\t\n",
       "test data, v-channel, standard deviation: 0.86127668997906\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--classes={'bridge', 'building', 'city', 'eiffel_tower','elephant', 'landscape', 'lion', 'monkey', 'people', 'tower', 'water'}\n",
    "totaltest = 0\n",
    "for dir in paths.iterdirs(\"./dataset/val/\") do\n",
    "    files = {}\n",
    "    print(files)\n",
    "    for file in paths.files(paths.concat('./dataset/val/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, 1)\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "    print(totaltest)\n",
    "    totaltest = totaltest + #files\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print('total', totaltest)\n",
    "\n",
    "imagesAll = torch.Tensor(totaltest,3,64,64) \n",
    "labelsAll = torch.Tensor(totaltest)\n",
    "compteur = 0\n",
    "NumberOfImages = {0}\n",
    "for dir in paths.iterdirs(\"./dataset/val/\") do\n",
    "    compteur = compteur +1\n",
    "    files = {}\n",
    "    for file in paths.files(paths.concat('./dataset/val/', dir)) do\n",
    "       if file:find('JPEG' .. '$') then\n",
    "          table.insert(files, paths.concat(paths.concat('./dataset/val/',dir), file))\n",
    "       end\n",
    "    end\n",
    "   \n",
    "    if #files == 0 then\n",
    "       error('given directory doesnt contain any files of type: ')\n",
    "    end\n",
    "\n",
    "    lastElement = NumberOfImages[#NumberOfImages]\n",
    "    table.insert(NumberOfImages, #files + lastElement)\n",
    "    for i=1,(#files) do\n",
    "        temp = image.load(files[i])\n",
    "        temp2 = torch.Tensor(3,64,64) \n",
    "        if (temp:size()[1]==1) then\n",
    "            temp2[{{1},{},{}}] = temp\n",
    "            temp2[{{2},{},{}}] = temp\n",
    "            temp2[{{3},{},{}}] = temp\n",
    "        else \n",
    "            temp2 = temp\n",
    "        end\n",
    "        imagesAll[i+lastElement] = temp2 \n",
    "        labelsAll[i+lastElement] = compteur\n",
    "    end\n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "\n",
    "-- Nombre d'images courleurs: 1683 \n",
    "testData = {\n",
    "    data = torch.Tensor(totaltest, 3, 64, 64),\n",
    "    labels = torch.Tensor(totaltest),\n",
    "    size = function() return totaltest end,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "for i=1,totaltest do\n",
    "   testData.data[i] = imagesAll[i]\n",
    "   testData.labels[i] = labelsAll[i]\n",
    "end\n",
    "\n",
    "-- Convert all images to YUV\n",
    "print '==> preprocessing data: colorspace RGB -> YUV'\n",
    "for i = 1,totaltest do\n",
    "   testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "end\n",
    "--for i = 1,325 do\n",
    "  -- testData.data[i] = image.rgb2yuv(testData.data[i])\n",
    "--end\n",
    "-- Name channels for convenience\n",
    "channels = {'y','u','v'}\n",
    "\n",
    "-- Normalize each channel, and store mean/std\n",
    "-- per channel. These values are important, as they are part of\n",
    "-- the trainable parameters. At test time, test data will be normalized\n",
    "-- using these values.\n",
    "print '==> preprocessing data: normalize each feature (channel) globally'\n",
    "--mean = {}\n",
    "--std = {}\n",
    "for i,channel in ipairs(channels) do\n",
    "   -- normalize each channel globally:\n",
    "   testData.data[{ {},i,{},{} }]:add(-mean[i])\n",
    "   testData.data[{ {},i,{},{} }]:div(std[i])\n",
    "end\n",
    "\n",
    "-- Local normalization\n",
    "print '==> preprocessing data: normalize all three channels locally'\n",
    "\n",
    "-- Define the normalization neighborhood:\n",
    "neighborhood = image.gaussian1D(13)\n",
    "\n",
    "-- Define our local normalization operator (It is an actual nn module, \n",
    "-- which could be inserted into a trainable model):\n",
    "normalization = nn.SpatialContrastiveNormalization(1, neighborhood)\n",
    "\n",
    "-- Normalize all channels locally:\n",
    "for c in ipairs(channels) do\n",
    "\n",
    "   for i = 1,totaltest do\n",
    "      testData.data[{ i,{c},{},{} }] = normalization:forward(testData.data[{ i,{c},{},{} }])\n",
    "   end\n",
    "end\n",
    "\n",
    "print '==> verify statistics'\n",
    "for i,channel in ipairs(channels) do\n",
    "\n",
    "   testMean = testData.data[{ {},i }]:mean()\n",
    "   testStd = testData.data[{ {},i }]:std()\n",
    "\n",
    "\n",
    "   print('test data, '..channel..'-channel, mean: ' .. testMean)\n",
    "   print('test data, '..channel..'-channel, standard deviation: ' .. testStd)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- test function\n",
    "function test(dataset)\n",
    "\n",
    "   -- test over given dataset\n",
    "   print('<trainer> on testing Set:')\n",
    "   for t = 1,dataset:size() do\n",
    "      -- get new sample\n",
    "      local input = dataset.data[t]\n",
    "      local target = dataset.labels[t]\n",
    "\n",
    "      -- test sample\n",
    "      local pred = model:forward(input)\n",
    "      confusion:add(pred, target)\n",
    "   end\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "   confusion:zero()\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 1 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     125       0       1      32       0       0       9      15       0       0       0]   68.681% \t[class: bridge]\n",
       " [     138      19       0       0       0       0       0       0       0       0       0]   12.102% \t[class: building]\n",
       " [       0      85       0       0       0       0       0       0       0       0       0]   0.000% \t[class: city]\n",
       " [       0      17       0       0       0       0       0       0       0       0       0]   0.000% \t[class: eiffel_tower]\n",
       " [       1     133       1       0      88       0       0       0       0       0       0]   39.462% \t[class: elephant]\n",
       " [       0       0       0       0      44       0       0       0       0       0       0]   0.000% \t[class: landscape]\n",
       " [       0       0       0       0     163       0     125       0       0       0       0]   43.403% \t[class: lion]\n",
       " [       0       0       0       0       0       0     206       9       0       0       0]   4.186% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       5     159       0       0       0]   0.000% \t[class: people]\n",
       " [       0       0       0       0       0       0       1     113      39       0       0]   0.000% \t[class: tower]\n",
       " [       0       0       0       0       0       0       3     110      71       5       1]]  0.526% \t[class: water]\n",
       " + average row correct: 15.305477626283% \n",
       " + average rowUcol correct (VOC measure): 8.2421666011214% \n",
       " + global correct: 21.362048894063%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.082421666011214\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.15305477626283\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.21362048894063\n",
       "}\n",
       "<trainer> on testing Set:\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: bridge]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: building]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: city]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: eiffel_tower]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: elephant]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: landscape]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: lion]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: people]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: tower]\n",
       " [       0       0       0       0       0       0       0       0       0       0       0]]  nan% \t[class: water]\n",
       " + average row correct: 0% \n",
       " + average rowUcol correct (VOC measure): 0% \n",
       " + global correct: 0%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 2 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[       9       0       0       0       0       0       0       0       0       0     173]   4.945% \t[class: bridge]\n",
       " [     148       3       0       0       0       0       0       0       0       0       6]   1.911% \t[class: building]\n",
       " [      66      18       0       0       0       0       0       0       0       0       1]   0.000% \t[class: city]\n",
       " [      11       6       0       0       0       0       0       0       0       0       0]   0.000% \t[class: eiffel_tower]\n",
       " [      87      69       0       0      65       0       0       0       0       0       2]   29.148% \t[class: elephant]\n",
       " [       0       0       0       0      44       0       0       0       0       0       0]   0.000% \t[class: landscape]\n",
       " [       0       0       0       0     193       0      95       0       0       0       0]   32.986% \t[class: lion]\n",
       " [       0       0       0       0       0       0     215       0       0       0       0]   0.000% \t[class: monkey]\n",
       " [       0       0       0       0       0       0      58     106       0       0       0]   0.000% \t[class: people]\n",
       " [       0       0       0       0       0       0      38     103      12       0       0]   0.000% \t[class: tower]\n",
       " [       0       0       0       0       0       0      56     103      22       0       9]]  4.737% \t[class: water]\n",
       " + average row correct: 6.7024380307306% \n",
       " + average rowUcol correct (VOC measure): 3.0977698889646% \n",
       " + global correct: 10.535506402794%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0.030977698889646\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0.067024380307306\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       "  nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0.10535506402794\n",
       "}\n",
       "<trainer> on testing Set:\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: bridge]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: building]\n",
       " [       0       0       0       0       0       0       0       1       0       0      31]   0.000% \t[class: city]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: eiffel_tower]\n",
       " [       0       0       0       0       0       0       1       0       0       0      31]   0.000% \t[class: elephant]\n",
       " [       0       0       0       0       0       0       1       0       0       0      31]   0.000% \t[class: landscape]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: lion]\n",
       " [       0       0       0       0       0       0       0       0       0       0      32]   0.000% \t[class: monkey]\n",
       " [       0       0       0       0       0       0       0       1       0       0      31]   0.000% \t[class: people]\n",
       " [       0       0       0       0       0       0       1       1       0       0      30]   0.000% \t[class: tower]\n",
       " [       0       0       0       0       0       0       0       0       0       0       0]]  nan% \t[class: water]\n",
       " + average row correct: 0% \n",
       " + average rowUcol correct (VOC measure): 0% \n",
       " + global correct: 0%\n",
       "{\n",
       "  valids : FloatTensor - size: 11\n",
       "  mat : LongTensor - size: 11x11\n",
       "  averageUnionValid : 0\n",
       "  _targ_idx : LongTensor - empty\n",
       "  averageValid : 0\n",
       "  classes : \n",
       "    {\n",
       "      1 : bridge\n",
       "      2 : building\n",
       "      3 : city\n",
       "      4 : eiffel_tower\n",
       "      5 : elephant\n",
       "      6 : landscape\n",
       "      7 : lion\n",
       "      8 : monkey\n",
       "      9 : people\n",
       "      10 : tower\n",
       "      11 : water\n",
       "    }\n",
       "  _prediction : FloatTensor - size: 11\n",
       "  _pred_idx : LongTensor - size: 1\n",
       " "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " nclasses : 11\n",
       "  _max : FloatTensor - size: 1\n",
       "  _target : FloatTensor - empty\n",
       "  unionvalids : FloatTensor - size: 11\n",
       "  totalValid : 0\n",
       "}\n",
       "<trainer> on training set:\t\n",
       "<trainer> online epoch # 3 [batchSize = 64]\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "while i<10 do\n",
    "train(trainData)\n",
    "test(testData)\n",
    "i=i+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
